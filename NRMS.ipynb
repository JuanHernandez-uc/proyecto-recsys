{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W5eMFDfIkSQQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_behaviors = pd.read_csv(\"behaviors.tsv\", sep=\"\\t\", names=['ImpressionID', 'UserID', 'Time', 'History', 'Impressions'])\n",
        "df_news = pd.read_csv(\"news.tsv\", sep=\"\\t\", names=['NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'TitleEntities', 'AbstractEntities'])"
      ],
      "metadata": {
        "id": "lL0Ij4TmkxK3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_behaviors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie1aNADnh5ZR",
        "outputId": "3c3f406b-cf5a-49c3-d703-9fdec6d00343"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156965, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_behaviors[\"Time\"] = pd.to_datetime(df_behaviors[\"Time\"])\n",
        "cutoff = pd.to_datetime(\"2019-11-14\")\n",
        "\n",
        "behavior_train = df_behaviors[df_behaviors[\"Time\"] < cutoff].copy()\n",
        "behavior_val   = df_behaviors[df_behaviors[\"Time\"] >= cutoff].copy()"
      ],
      "metadata": {
        "id": "aYJ9dhTEk5jN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Usando dispositivo: {device}')"
      ],
      "metadata": {
        "id": "O7FV8zuBTgN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dba35e8-2856-4031-8598-2abb0d5763ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    tokens = re.findall(r\"[\\w']+\", text.lower())\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "DqZFd1fdTiUI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "longitudes = df_news[\"Title\"].dropna().apply(lambda x: len(x.split()))\n",
        "cantidad_menor_20 = (longitudes < 20).sum()\n",
        "total = len(longitudes)\n",
        "\n",
        "print(f\"Títulos con menos de 20 palabras: {cantidad_menor_20} de {total} ({cantidad_menor_20 / total:.2%})\")"
      ],
      "metadata": {
        "id": "ENnlGkbhU0dG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb3e899-c9ea-4d4a-f7d6-2e666811050d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Títulos con menos de 20 palabras: 50633 de 51282 (98.73%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
        "idx = 2 # Por <UNK> y <PAD>\n",
        "news2idx = {}  # Mapeo: news_id -> lista de índices de palabras (padded/trunc)\n",
        "max_size_title = 20"
      ],
      "metadata": {
        "id": "Cr17bxtBV52Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in tqdm(df_news.iterrows(), total=df_news.shape[0]):\n",
        "    news_id = row[\"NewsID\"]\n",
        "    title = row[\"Title\"]\n",
        "    tokens = [] if pd.isna(title) else tokenize(title)\n",
        "    token_idxs = []\n",
        "    for w in tokens[:max_size_title]:  # truncar título largo\n",
        "        if w not in word2idx:\n",
        "            word2idx[w] = idx\n",
        "            idx += 1\n",
        "        token_idxs.append(word2idx.get(w, word2idx['<UNK>']))\n",
        "    # Rellenar con PAD si es más corto que title_max\n",
        "    if len(token_idxs) < max_size_title:\n",
        "        token_idxs += [word2idx['<PAD>']] * (max_size_title - len(token_idxs))\n",
        "    news2idx[news_id] = token_idxs"
      ],
      "metadata": {
        "id": "3ePeLaQfVduC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa400ac7-936b-40dc-ba3d-192ec8c6c3c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51282/51282 [00:02<00:00, 18281.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word2idx)\n",
        "print(f'Vocabulario: {vocab_size} palabras')"
      ],
      "metadata": {
        "id": "YzJUN1lvWU34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0628b23-4e22-4bfe-edc5-96eda507afe8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario: 37272 palabras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for _, row in tqdm(behavior_train.iterrows(), total=behavior_train.shape[0]):\n",
        "    hist_str = row['History']\n",
        "    hist_ids = [] if pd.isna(hist_str) else [nid for nid in hist_str.split() if nid]\n",
        "    impr = row['ImpressionID']\n",
        "    imps = [] if pd.isna(row['Impressions']) else row['Impressions'].split()\n",
        "    for imp in imps:\n",
        "        if len(imp) == 0:\n",
        "            continue\n",
        "        parts = imp.split('-')\n",
        "        if len(parts) != 2:\n",
        "            continue\n",
        "        news_id, click = parts[0], parts[1]\n",
        "        label = int(click)\n",
        "        data.append((impr, hist_ids, news_id, label))"
      ],
      "metadata": {
        "id": "QoCzTq-vWccd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc919dc0-6d3c-40c8-922c-fd5a2ace4126"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 126695/126695 [00:15<00:00, 8129.15it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[:460000]"
      ],
      "metadata": {
        "id": "YeqSSwr0P2rT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total de ejemplos de interacción: {len(data)}')"
      ],
      "metadata": {
        "id": "x5FWH_6lW9Le",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d51307-f6a7-4fcf-80f3-40c06b1f0069"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de ejemplos de interacción: 460000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = []\n",
        "\n",
        "for _, row in tqdm(behavior_val.iterrows(), total=behavior_val.shape[0]):\n",
        "    hist_str = row['History']\n",
        "    hist_ids = [] if pd.isna(hist_str) else [nid for nid in hist_str.split() if nid]\n",
        "    impr = row['ImpressionID']\n",
        "    imps = row['Impressions'].split()\n",
        "    for imp in imps:\n",
        "        if len(imp) == 0:\n",
        "            continue\n",
        "        parts = imp.split('-')\n",
        "        if len(parts) != 2:\n",
        "            continue\n",
        "        news_id, click = parts[0], parts[1]\n",
        "        val_data.append((impr, hist_ids, news_id, int(click)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MNHr5cLrw8H",
        "outputId": "f4bdb4d9-28da-447b-fac2-5074d2b3bdb4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30270/30270 [00:03<00:00, 8887.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = val_data[:120000]"
      ],
      "metadata": {
        "id": "xnh-ZDyOP-LB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total ejemplos validación: {len(val_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d36pXQwyr5go",
        "outputId": "6de1730e-de34-4f5c-978c-affc1df65d2a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total ejemplos validación: 120000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MINDDataset(Dataset):\n",
        "    def __init__(self, interactions, news2idx, word2idx, hist_max, title_max):\n",
        "        self.interactions = interactions\n",
        "        self.news2idx = news2idx\n",
        "        self.word2idx = word2idx\n",
        "        self.hist_max = hist_max\n",
        "        self.title_max = title_max\n",
        "    def __len__(self):\n",
        "        return len(self.interactions)\n",
        "    def __getitem__(self, idx):\n",
        "        impr, hist_ids, cand_id, label = self.interactions[idx]\n",
        "        # Truncar o pad historial\n",
        "        if len(hist_ids) > self.hist_max:\n",
        "            hist_ids = hist_ids[-self.hist_max:]\n",
        "        hist_seq = []\n",
        "        for nid in hist_ids:\n",
        "            seq = self.news2idx.get(nid, [self.word2idx['<PAD>']] * self.title_max)\n",
        "            hist_seq.append(seq)\n",
        "        if len(hist_seq) < self.hist_max:\n",
        "            pad_seq = [self.word2idx['<PAD>']] * self.title_max\n",
        "            for _ in range(self.hist_max - len(hist_seq)):\n",
        "                hist_seq.insert(0, pad_seq)\n",
        "        # Noticia candidata\n",
        "        cand_seq = self.news2idx.get(cand_id, [self.word2idx['<PAD>']] * self.title_max)\n",
        "        # Convertir a tensores\n",
        "        hist_tensor = torch.tensor(hist_seq, dtype=torch.long)\n",
        "        cand_tensor = torch.tensor(cand_seq, dtype=torch.long)\n",
        "        label_tensor = torch.tensor(label, dtype=torch.float)\n",
        "        return hist_tensor, cand_tensor, label_tensor, impr"
      ],
      "metadata": {
        "id": "IdKBDf4EXADq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    hist_list, cand_list, label_list, impr_list = zip(*batch)\n",
        "    hist_batch = torch.stack(hist_list)        # (batch, hist_max, title_max)\n",
        "    cand_batch = torch.stack(cand_list)        # (batch, title_max)\n",
        "    label_batch = torch.stack(label_list).view(-1,1)\n",
        "    impr_batch = list(impr_list)\n",
        "    return hist_batch.to(device), cand_batch.to(device), label_batch.to(device), impr_batch"
      ],
      "metadata": {
        "id": "_4Iiwna9rTP0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_hist_title = 50\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "orQi2EU7sRZT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MINDDataset(data, news2idx, word2idx, max_hist_title, max_size_title)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "val_dataset = MINDDataset(val_data, news2idx, word2idx, max_hist_title, max_size_title)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "HITyQvzvrUxg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = None"
      ],
      "metadata": {
        "id": "1_ScmTrZth42"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, title_max, pretrained_emb=None):\n",
        "        super(NewsEncoder, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=word2idx['<PAD>'])\n",
        "        if pretrained_emb is not None:\n",
        "            self.embed.weight.data.copy_(pretrained_emb)\n",
        "            self.embed.weight.requires_grad = True\n",
        "        self.word_attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
        "        self.Ww = nn.Linear(embed_dim, embed_dim)\n",
        "        self.qw = nn.Linear(embed_dim, 1, bias=False)\n",
        "    def forward(self, x):\n",
        "        emb = self.embed(x)  # (batch, title_max, embed_dim)\n",
        "        attn_out, _ = self.word_attn(emb, emb, emb)  # atención self-word\n",
        "        M = torch.tanh(self.Ww(attn_out))\n",
        "        alpha = torch.softmax(self.qw(M).squeeze(-1), dim=1)\n",
        "        r = torch.sum(attn_out * alpha.unsqueeze(-1), dim=1)  # (batch, embed_dim)\n",
        "        return r\n",
        "\n",
        "class UserEncoder(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super(UserEncoder, self).__init__()\n",
        "        self.news_attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
        "        self.Wn = nn.Linear(embed_dim, embed_dim)\n",
        "        self.qn = nn.Linear(embed_dim, 1, bias=False)\n",
        "    def forward(self, news_vecs):\n",
        "        attn_out, _ = self.news_attn(news_vecs, news_vecs, news_vecs)  # atención entre noticias\n",
        "        M = torch.tanh(self.Wn(attn_out))\n",
        "        beta = torch.softmax(self.qn(M).squeeze(-1), dim=1)\n",
        "        u = torch.sum(attn_out * beta.unsqueeze(-1), dim=1)  # (batch, embed_dim)\n",
        "        return u\n",
        "\n",
        "class NRMS(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, title_max, hist_max, pretrained_emb=None):\n",
        "        super(NRMS, self).__init__()\n",
        "        self.news_encoder = NewsEncoder(vocab_size, embed_dim, num_heads, title_max, pretrained_emb)\n",
        "        self.user_encoder = UserEncoder(embed_dim, num_heads)\n",
        "    def forward(self, hist, cand):\n",
        "        batch_size = hist.size(0)\n",
        "        hist_flat = hist.view(-1, hist.size(2))  # (batch*hist_max, title_max)\n",
        "        hist_vecs = self.news_encoder(hist_flat)  # (batch*hist_max, embed_dim)\n",
        "        hist_vecs = hist_vecs.view(batch_size, -1, hist_vecs.size(-1))  # (batch, hist_max, embed_dim)\n",
        "        user_vec = self.user_encoder(hist_vecs)   # (batch, embed_dim)\n",
        "        cand_vec = self.news_encoder(cand)        # (batch, embed_dim)\n",
        "        score = torch.sum(user_vec * cand_vec, dim=1)  # (batch,)\n",
        "        return score  # logits"
      ],
      "metadata": {
        "id": "sIWNLWqjtibN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 300\n",
        "num_heads = 10\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "MM20oT6xt5-Y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NRMS(vocab_size, embed_dim, num_heads, max_size_title, max_hist_title,\n",
        "             pretrained_emb=embedding_matrix.to(device) if embedding_matrix is not None else None)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "0Hu00prQt3W6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ndcg_score(labels, scores, k=5):\n",
        "    order = np.argsort(scores)[::-1]\n",
        "    labels = np.array(labels)\n",
        "    dcg = 0.0\n",
        "    for i in range(min(k, len(labels))):\n",
        "        rel = labels[order[i]]\n",
        "        dcg += (2**rel - 1) / np.log2(i+2)\n",
        "    ideal = np.sort(labels)[::-1]\n",
        "    idcg = 0.0\n",
        "    for i in range(min(k, int(np.sum(labels)))):\n",
        "        idcg += 1.0 / np.log2(i+2)\n",
        "    return dcg / idcg if idcg > 0 else 0.0"
      ],
      "metadata": {
        "id": "r1CVNj4muLfr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3"
      ],
      "metadata": {
        "id": "mz630hGWuWkM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for hist_batch, cand_batch, label_batch, _ in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(hist_batch, cand_batch)\n",
        "        loss = criterion(scores, label_batch.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch} - Pérdida promedio: {avg_loss:.4f}\")\n",
        "    # Evaluación en validación\n",
        "    if val_loader is not None:\n",
        "        model.eval()\n",
        "        all_preds = {}\n",
        "        with torch.no_grad():\n",
        "            for hist_batch, cand_batch, label_batch, impr_batch in val_loader:\n",
        "                scores = model(hist_batch, cand_batch).cpu().numpy()\n",
        "                labels = label_batch.cpu().numpy().flatten()\n",
        "                for impr_id, s, l in zip(impr_batch, scores, labels):\n",
        "                    all_preds.setdefault(impr_id, []).append((s,l))\n",
        "        # Calcular métricas en validación\n",
        "        correct, total = 0, 0\n",
        "        ndcg5_list = []\n",
        "        for impr_id, recs in all_preds.items():\n",
        "            scores = [s for (s,l) in recs]\n",
        "            labels = [l for (s,l) in recs]\n",
        "            preds_bin = [1 if s>=0.0 else 0 for s in scores]\n",
        "            correct += sum(int(p==l) for p,l in zip(preds_bin, labels))\n",
        "            total += len(labels)\n",
        "            ndcg5_list.append(ndcg_score(labels, scores, k=5))\n",
        "        acc = correct / total if total>0 else 0\n",
        "        ndcg5 = np.mean(ndcg5_list) if ndcg5_list else 0\n",
        "        print(f\"Validación - Accuracy: {acc:.4f}, nDCG@5: {ndcg5:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "K9c_i2TSuPaq",
        "outputId": "eee09d6c-0ec8-45b3-9a65-2b95b198cfd3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/3: 100%|██████████| 3594/3594 [14:38<00:00,  4.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Pérdida promedio: 0.1694\n",
            "Validación - Accuracy: 0.9624, nDCG@5: 0.2184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 3594/3594 [14:42<00:00,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Pérdida promedio: 0.1620\n",
            "Validación - Accuracy: 0.9624, nDCG@5: 0.2256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3:  15%|█▌        | 557/3594 [02:16<12:26,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-a4240ed0e9ac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch} - Pérdida promedio: {avg_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}