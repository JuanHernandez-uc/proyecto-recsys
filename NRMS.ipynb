{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W5eMFDfIkSQQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a4a24397-28b3-4672-a2f5-e11243673871"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9a15c8901564>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_behaviors = pd.read_csv(\"behaviors_sample.tsv\", sep=\"\\t\", names=['ImpressionID', 'UserID', 'Time', 'History', 'Impressions'])\n",
        "df_news = pd.read_csv(\"news_sample.tsv\", sep=\"\\t\", names=['NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'TitleEntities', 'AbstractEntities'])"
      ],
      "metadata": {
        "id": "lL0Ij4TmkxK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_behaviors.shape"
      ],
      "metadata": {
        "id": "Ie1aNADnh5ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_behaviors[\"Time\"] = pd.to_datetime(df_behaviors[\"Time\"])\n",
        "cutoff = pd.to_datetime(\"2019-11-14\")\n",
        "\n",
        "behavior_train = df_behaviors[df_behaviors[\"Time\"] < cutoff].copy()\n",
        "behavior_val   = df_behaviors[df_behaviors[\"Time\"] >= cutoff].copy()"
      ],
      "metadata": {
        "id": "aYJ9dhTEk5jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Usando dispositivo: {device}')"
      ],
      "metadata": {
        "id": "O7FV8zuBTgN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    tokens = re.findall(r\"[\\w']+\", text.lower())\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "DqZFd1fdTiUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "longitudes = df_news[\"Title\"].dropna().apply(lambda x: len(x.split()))\n",
        "cantidad_menor_20 = (longitudes < 20).sum()\n",
        "total = len(longitudes)\n",
        "\n",
        "print(f\"Títulos con menos de 20 palabras: {cantidad_menor_20} de {total} ({cantidad_menor_20 / total:.2%})\")"
      ],
      "metadata": {
        "id": "ENnlGkbhU0dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
        "idx = 2 # Por <UNK> y <PAD>\n",
        "news2idx = {}  # Mapeo: news_id -> lista de índices de palabras (padded/trunc)\n",
        "max_size_title = 20"
      ],
      "metadata": {
        "id": "Cr17bxtBV52Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in tqdm(df_news.iterrows(), total=df_news.shape[0]):\n",
        "    news_id = row[\"NewsID\"]\n",
        "    title = row[\"Title\"]\n",
        "    tokens = [] if pd.isna(title) else tokenize(title)\n",
        "    token_idxs = []\n",
        "    for w in tokens[:max_size_title]:  # truncar título largo\n",
        "        if w not in word2idx:\n",
        "            word2idx[w] = idx\n",
        "            idx += 1\n",
        "        token_idxs.append(word2idx.get(w, word2idx['<UNK>']))\n",
        "    # Rellenar con PAD si es más corto que title_max\n",
        "    if len(token_idxs) < max_size_title:\n",
        "        token_idxs += [word2idx['<PAD>']] * (max_size_title - len(token_idxs))\n",
        "    news2idx[news_id] = token_idxs"
      ],
      "metadata": {
        "id": "3ePeLaQfVduC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word2idx)\n",
        "print(f'Vocabulario: {vocab_size} palabras')"
      ],
      "metadata": {
        "id": "YzJUN1lvWU34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for _, row in tqdm(behavior_train.iterrows(), total=behavior_train.shape[0]):\n",
        "    hist_str = row['History']\n",
        "    hist_ids = [] if pd.isna(hist_str) else [nid for nid in hist_str.split() if nid]\n",
        "    impr = row['ImpressionID']\n",
        "    imps = [] if pd.isna(row['Impressions']) else row['Impressions'].split()\n",
        "    for imp in imps:\n",
        "        if len(imp) == 0:\n",
        "            continue\n",
        "        parts = imp.split('-')\n",
        "        if len(parts) != 2:\n",
        "            continue\n",
        "        news_id, click = parts[0], parts[1]\n",
        "        label = int(click)\n",
        "        data.append((impr, hist_ids, news_id, label))"
      ],
      "metadata": {
        "id": "QoCzTq-vWccd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = data[:460000]"
      ],
      "metadata": {
        "id": "YeqSSwr0P2rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total de ejemplos de interacción: {len(data)}')"
      ],
      "metadata": {
        "id": "x5FWH_6lW9Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = []\n",
        "\n",
        "for _, row in tqdm(behavior_val.iterrows(), total=behavior_val.shape[0]):\n",
        "    hist_str = row['History']\n",
        "    hist_ids = [] if pd.isna(hist_str) else [nid for nid in hist_str.split() if nid]\n",
        "    impr = row['ImpressionID']\n",
        "    imps = row['Impressions'].split()\n",
        "    for imp in imps:\n",
        "        if len(imp) == 0:\n",
        "            continue\n",
        "        parts = imp.split('-')\n",
        "        if len(parts) != 2:\n",
        "            continue\n",
        "        news_id, click = parts[0], parts[1]\n",
        "        val_data.append((impr, hist_ids, news_id, int(click)))"
      ],
      "metadata": {
        "id": "6MNHr5cLrw8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# val_data = val_data[:120000]"
      ],
      "metadata": {
        "id": "xnh-ZDyOP-LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total ejemplos validación: {len(val_data)}')"
      ],
      "metadata": {
        "id": "d36pXQwyr5go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MINDDataset(Dataset):\n",
        "    def __init__(self, interactions, news2idx, word2idx, hist_max, title_max):\n",
        "        self.interactions = interactions\n",
        "        self.news2idx = news2idx\n",
        "        self.word2idx = word2idx\n",
        "        self.hist_max = hist_max\n",
        "        self.title_max = title_max\n",
        "    def __len__(self):\n",
        "        return len(self.interactions)\n",
        "    def __getitem__(self, idx):\n",
        "        impr, hist_ids, cand_id, label = self.interactions[idx]\n",
        "        # Truncar o pad historial\n",
        "        if len(hist_ids) > self.hist_max:\n",
        "            hist_ids = hist_ids[-self.hist_max:]\n",
        "        hist_seq = []\n",
        "        for nid in hist_ids:\n",
        "            seq = self.news2idx.get(nid, [self.word2idx['<PAD>']] * self.title_max)\n",
        "            hist_seq.append(seq)\n",
        "        if len(hist_seq) < self.hist_max:\n",
        "            pad_seq = [self.word2idx['<PAD>']] * self.title_max\n",
        "            for _ in range(self.hist_max - len(hist_seq)):\n",
        "                hist_seq.insert(0, pad_seq)\n",
        "        # Noticia candidata\n",
        "        cand_seq = self.news2idx.get(cand_id, [self.word2idx['<PAD>']] * self.title_max)\n",
        "        # Convertir a tensores\n",
        "        hist_tensor = torch.tensor(hist_seq, dtype=torch.long)\n",
        "        cand_tensor = torch.tensor(cand_seq, dtype=torch.long)\n",
        "        label_tensor = torch.tensor(label, dtype=torch.float)\n",
        "        return hist_tensor, cand_tensor, label_tensor, impr"
      ],
      "metadata": {
        "id": "IdKBDf4EXADq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    hist_list, cand_list, label_list, impr_list = zip(*batch)\n",
        "    hist_batch = torch.stack(hist_list)        # (batch, hist_max, title_max)\n",
        "    cand_batch = torch.stack(cand_list)        # (batch, title_max)\n",
        "    label_batch = torch.stack(label_list).view(-1,1)\n",
        "    impr_batch = list(impr_list)\n",
        "    return hist_batch.to(device), cand_batch.to(device), label_batch.to(device), impr_batch"
      ],
      "metadata": {
        "id": "_4Iiwna9rTP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_hist_title = 50\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "orQi2EU7sRZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MINDDataset(data, news2idx, word2idx, max_hist_title, max_size_title)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "val_dataset = MINDDataset(val_data, news2idx, word2idx, max_hist_title, max_size_title)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "HITyQvzvrUxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 300\n",
        "num_heads = 10\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "9ysEHlz1hwXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove = False\n",
        "\n",
        "if glove:\n",
        "    embedding_matrix = np.random.normal(scale=0.6, size=(vocab_size, embed_dim))\n",
        "    found = 0\n",
        "    with open(\"glove.6B.300d.txt\", 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.rstrip().split(' ')\n",
        "            word = parts[0]\n",
        "            if word in word2idx:\n",
        "                vec = np.array(parts[1:], dtype=np.float32)\n",
        "                if vec.shape[0] == embed_dim:\n",
        "                    embedding_matrix[word2idx[word]] = vec\n",
        "                    found += 1\n",
        "    print(f'Palabras encontradas en GloVe: {found}/{vocab_size}')\n",
        "    embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float)\n",
        "else:\n",
        "    embedding_matrix = None"
      ],
      "metadata": {
        "id": "1_ScmTrZth42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, title_max, pretrained_emb=None):\n",
        "        super(NewsEncoder, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=word2idx['<PAD>'])\n",
        "        if pretrained_emb is not None:\n",
        "            self.embed.weight.data.copy_(pretrained_emb)\n",
        "            self.embed.weight.requires_grad = True\n",
        "        self.word_attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
        "        self.Ww = nn.Linear(embed_dim, embed_dim)\n",
        "        self.qw = nn.Linear(embed_dim, 1, bias=False)\n",
        "    def forward(self, x):\n",
        "        emb = self.embed(x)  # (batch, title_max, embed_dim)\n",
        "        attn_out, _ = self.word_attn(emb, emb, emb)  # atención self-word\n",
        "        M = torch.tanh(self.Ww(attn_out))\n",
        "        alpha = torch.softmax(self.qw(M).squeeze(-1), dim=1)\n",
        "        r = torch.sum(attn_out * alpha.unsqueeze(-1), dim=1)  # (batch, embed_dim)\n",
        "        return r\n",
        "\n",
        "class UserEncoder(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super(UserEncoder, self).__init__()\n",
        "        self.news_attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
        "        self.Wn = nn.Linear(embed_dim, embed_dim)\n",
        "        self.qn = nn.Linear(embed_dim, 1, bias=False)\n",
        "    def forward(self, news_vecs):\n",
        "        attn_out, _ = self.news_attn(news_vecs, news_vecs, news_vecs)  # atención entre noticias\n",
        "        M = torch.tanh(self.Wn(attn_out))\n",
        "        beta = torch.softmax(self.qn(M).squeeze(-1), dim=1)\n",
        "        u = torch.sum(attn_out * beta.unsqueeze(-1), dim=1)  # (batch, embed_dim)\n",
        "        return u\n",
        "\n",
        "class NRMS(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, title_max, hist_max, pretrained_emb=None):\n",
        "        super(NRMS, self).__init__()\n",
        "        self.news_encoder = NewsEncoder(vocab_size, embed_dim, num_heads, title_max, pretrained_emb)\n",
        "        self.user_encoder = UserEncoder(embed_dim, num_heads)\n",
        "    def forward(self, hist, cand):\n",
        "        batch_size = hist.size(0)\n",
        "        hist_flat = hist.view(-1, hist.size(2))  # (batch*hist_max, title_max)\n",
        "        hist_vecs = self.news_encoder(hist_flat)  # (batch*hist_max, embed_dim)\n",
        "        hist_vecs = hist_vecs.view(batch_size, -1, hist_vecs.size(-1))  # (batch, hist_max, embed_dim)\n",
        "        user_vec = self.user_encoder(hist_vecs)   # (batch, embed_dim)\n",
        "        cand_vec = self.news_encoder(cand)        # (batch, embed_dim)\n",
        "        score = torch.sum(user_vec * cand_vec, dim=1)  # (batch,)\n",
        "        return score  # logits"
      ],
      "metadata": {
        "id": "sIWNLWqjtibN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NRMS(vocab_size, embed_dim, num_heads, max_size_title, max_hist_title,\n",
        "             pretrained_emb=embedding_matrix.to(device) if embedding_matrix is not None else None)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "0Hu00prQt3W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def ndcg_score(labels, scores, k=5):\n",
        "    order = np.argsort(scores)[::-1]\n",
        "    labels = np.array(labels)\n",
        "    dcg = 0.0\n",
        "    for i in range(min(k, len(labels))):\n",
        "        rel = labels[order[i]]\n",
        "        dcg += (2**rel - 1) / np.log2(i+2)\n",
        "    ideal = np.sort(labels)[::-1]\n",
        "    idcg = 0.0\n",
        "    for i in range(min(k, int(np.sum(labels)))):\n",
        "        idcg += 1.0 / np.log2(i+2)\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "def mrr_score(labels, scores):\n",
        "    order = np.argsort(scores)[::-1]\n",
        "    labels = np.array(labels)[order]\n",
        "    for rank, label in enumerate(labels, start=1):\n",
        "        if label == 1:\n",
        "            return 1.0 / rank\n",
        "    return 0.0\n"
      ],
      "metadata": {
        "id": "r1CVNj4muLfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3"
      ],
      "metadata": {
        "id": "mz630hGWuWkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_ndcg5 = 0.0\n",
        "best_model_state = None\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for hist_batch, cand_batch, label_batch, _ in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(hist_batch, cand_batch)\n",
        "        loss = criterion(scores, label_batch.view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch} - Pérdida promedio: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluación en validación\n",
        "    if val_loader is not None:\n",
        "        model.eval()\n",
        "        all_preds = {}\n",
        "        with torch.no_grad():\n",
        "            for hist_batch, cand_batch, label_batch, impr_batch in val_loader:\n",
        "                scores = model(hist_batch, cand_batch).cpu().numpy()\n",
        "                labels = label_batch.cpu().numpy().flatten()\n",
        "                for impr_id, s, l in zip(impr_batch, scores, labels):\n",
        "                    all_preds.setdefault(impr_id, []).append((s, l))\n",
        "\n",
        "        correct, total = 0, 0\n",
        "        ndcg5_list, ndcg10_list, mrr_list, auc_scores = [], [], [], []\n",
        "\n",
        "        for impr_id, recs in all_preds.items():\n",
        "            scores = [s for (s, l) in recs]\n",
        "            labels = [l for (s, l) in recs]\n",
        "\n",
        "            # Accuracy binaria\n",
        "            preds_bin = [1 if s >= 0.0 else 0 for s in scores]\n",
        "            correct += sum(int(p == l) for p, l in zip(preds_bin, labels))\n",
        "            total += len(labels)\n",
        "\n",
        "            # Métricas ranking\n",
        "            ndcg5_list.append(ndcg_score(labels, scores, k=5))\n",
        "            ndcg10_list.append(ndcg_score(labels, scores, k=10))\n",
        "            mrr_list.append(mrr_score(labels, scores))\n",
        "\n",
        "            # AUC por sesión (si hay al menos un positivo y un negativo)\n",
        "            if len(set(labels)) > 1:\n",
        "                auc_scores.append(roc_auc_score(labels, scores))\n",
        "\n",
        "        acc = correct / total if total > 0 else 0\n",
        "        ndcg5 = np.mean(ndcg5_list)\n",
        "        ndcg10 = np.mean(ndcg10_list)\n",
        "        mrr = np.mean(mrr_list)\n",
        "        auc = np.mean(auc_scores) if auc_scores else 0.0\n",
        "\n",
        "        if ndcg5 > best_ndcg5:\n",
        "            best_ndcg5 = ndcg5\n",
        "            best_model_state = model.state_dict()\n",
        "            print(f\"Nuevo mejor modelo guardado (nDCG@5 = {ndcg5:.4f})\")\n",
        "\n",
        "\n",
        "        print(f\"Validación - Accuracy: {acc:.4f}, AUC: {auc:.4f}, MRR: {mrr:.4f}, nDCG@5: {ndcg5:.4f}, nDCG@10: {ndcg10:.4f}, \")\n",
        "\n",
        "if best_model_state is not None:\n",
        "    torch.save(best_model_state, \"nrms_best.pt\")\n",
        "    print(f\"Modelo con mejor nDCG@5 guardado en nrms_best.pt\")"
      ],
      "metadata": {
        "id": "K9c_i2TSuPaq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}