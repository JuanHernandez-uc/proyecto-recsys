{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jRn7tAtvznt-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_behaviors = pd.read_csv(\"behaviors.tsv\", sep=\"\\t\", names=['ImpressionID', 'UserID', 'Time', 'History', 'Impressions'])\n",
        "df_news = pd.read_csv(\"news.tsv\", sep=\"\\t\", names=['NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'TitleEntities', 'AbstractEntities'])"
      ],
      "metadata": {
        "id": "1tPZIFG41D58"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_behaviors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-d0mvuo1Vn_",
        "outputId": "5977cf9d-74d1-472e-efc3-4b705ed7f76a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156965, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_behaviors[\"Time\"] = pd.to_datetime(df_behaviors[\"Time\"])\n",
        "cutoff = pd.to_datetime(\"2019-11-14\")\n",
        "\n",
        "behavior_train = df_behaviors[df_behaviors[\"Time\"] < cutoff].copy()\n",
        "behavior_val   = df_behaviors[df_behaviors[\"Time\"] >= cutoff].copy()"
      ],
      "metadata": {
        "id": "65S_yx1t1Wln"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Usando dispositivo: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TW6Z1YS1XjO",
        "outputId": "d8033eaa-4d3d-4b65-d032-2b18a5a9ee7b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    tokens = re.findall(r\"[\\w']+\", text.lower())\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "H50xqCYK1YhW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "longitudes = df_news[\"Title\"].dropna().apply(lambda x: len(x.split()))\n",
        "cantidad_menor_20 = (longitudes < 20).sum()\n",
        "total = len(longitudes)\n",
        "\n",
        "print(f\"Títulos con menos de 20 palabras: {cantidad_menor_20} de {total} ({cantidad_menor_20 / total:.2%})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE9Fzw-J1ZZO",
        "outputId": "87543919-0b72-47c5-d67a-b713c4c62ae2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Títulos con menos de 20 palabras: 50633 de 51282 (98.73%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
        "idx = 2 # Por <UNK> y <PAD>\n",
        "news2idx = {}  # Mapeo: news_id -> lista de índices de palabras (padded/trunc)\n",
        "max_size_title = 20"
      ],
      "metadata": {
        "id": "sWUBzwkT1ahW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in tqdm(df_news.iterrows(), total=df_news.shape[0]):\n",
        "    news_id = row[\"NewsID\"]\n",
        "    title = row[\"Title\"]\n",
        "    tokens = [] if pd.isna(title) else tokenize(title)\n",
        "    token_idxs = []\n",
        "    for w in tokens[:max_size_title]:  # truncar título largo\n",
        "        if w not in word2idx:\n",
        "            word2idx[w] = idx\n",
        "            idx += 1\n",
        "        token_idxs.append(word2idx.get(w, word2idx['<UNK>']))\n",
        "    # Rellenar con PAD si es más corto que title_max\n",
        "    if len(token_idxs) < max_size_title:\n",
        "        token_idxs += [word2idx['<PAD>']] * (max_size_title - len(token_idxs))\n",
        "    news2idx[news_id] = token_idxs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upo5CjpX1bW-",
        "outputId": "4623d9ad-aff3-430b-9667-07647fdc6897"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51282/51282 [00:02<00:00, 18946.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word2idx)\n",
        "print(f'Vocabulario: {vocab_size} palabras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUGgNd7o1can",
        "outputId": "1651563e-72ab-4d88-a3e2-1a9353061936"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario: 37272 palabras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for _, row in tqdm(behavior_train.iterrows(), total=behavior_train.shape[0]):\n",
        "    hist_str = row['History']\n",
        "    hist_ids = [] if pd.isna(hist_str) else [nid for nid in hist_str.split() if nid]\n",
        "    impr = row['ImpressionID']\n",
        "    imps = [] if pd.isna(row['Impressions']) else row['Impressions'].split()\n",
        "    for imp in imps:\n",
        "        if len(imp) == 0:\n",
        "            continue\n",
        "        parts = imp.split('-')\n",
        "        if len(parts) != 2:\n",
        "            continue\n",
        "        news_id, click = parts[0], parts[1]\n",
        "        label = int(click)\n",
        "        data.append((impr, hist_ids, news_id, label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFUNeOhO1djW",
        "outputId": "a58f3ba3-965b-4a81-e24e-78904a7d41b7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 126695/126695 [00:15<00:00, 8440.08it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total de ejemplos de interacción: {len(data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAJKAq511e2m",
        "outputId": "fb2359ed-7ae1-42a0-fdec-46a421b674d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de ejemplos de interacción: 4621015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = []\n",
        "\n",
        "for _, row in tqdm(behavior_val.iterrows(), total=behavior_val.shape[0]):\n",
        "    hist_str = row['History']\n",
        "    hist_ids = [] if pd.isna(hist_str) else [nid for nid in hist_str.split() if nid]\n",
        "    impr = row['ImpressionID']\n",
        "    imps = row['Impressions'].split()\n",
        "    for imp in imps:\n",
        "        if len(imp) == 0:\n",
        "            continue\n",
        "        parts = imp.split('-')\n",
        "        if len(parts) != 2:\n",
        "            continue\n",
        "        news_id, click = parts[0], parts[1]\n",
        "        val_data.append((impr, hist_ids, news_id, int(click)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p30Gw8JU1f7O",
        "outputId": "f75efe9b-43ee-423e-f181-6b17c2c56ba6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30270/30270 [00:03<00:00, 8494.21it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total ejemplos validación: {len(val_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4dB2RD61hH2",
        "outputId": "68885a73-96af-4d2c-c5ed-5a7dcd8865e1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total ejemplos validación: 1222429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MINDListDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Devuelve:\n",
        "        hist_tensor  : [hist_max, title_max]\n",
        "        cand_tensor  : [C,         title_max]\n",
        "        label_tensor : [C]  (0/1, un solo 1)\n",
        "        impr_id      : str\n",
        "    \"\"\"\n",
        "    def __init__(self, interactions, news2idx, word2idx,\n",
        "                 hist_max, title_max):\n",
        "        self.news2idx  = news2idx\n",
        "        self.word2idx  = word2idx\n",
        "        self.hist_max  = hist_max\n",
        "        self.title_max = title_max\n",
        "\n",
        "        # Agrupar ejemplos por impresión -----------------------------\n",
        "        sessions = defaultdict(list)\n",
        "        for impr, hist_ids, cand_id, label in interactions:\n",
        "            sessions[impr].append((hist_ids, cand_id, label))\n",
        "        self.impr_ids = list(sessions.keys())\n",
        "        self.sessions = sessions\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.impr_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        impr   = self.impr_ids[idx]\n",
        "        triples = self.sessions[impr]           # lista de (hist, cand, label)\n",
        "\n",
        "        # -------- historial (todos los candidatos comparten el mismo) -----\n",
        "        hist_ids = triples[0][0][-self.hist_max:]        # recorte por la derecha\n",
        "        hist_seq = [self.news2idx.get(nid,\n",
        "                    [self.word2idx['<PAD>']]*self.title_max) for nid in hist_ids]\n",
        "        while len(hist_seq) < self.hist_max:\n",
        "            hist_seq.insert(0, [self.word2idx['<PAD>']]*self.title_max)\n",
        "\n",
        "        # -------- candidatos + etiquetas -------------------------------\n",
        "        cand_seqs, labels = [], []\n",
        "        for _, cand_id, lbl in triples:\n",
        "            cand_seqs.append(\n",
        "                self.news2idx.get(cand_id,\n",
        "                     [self.word2idx['<PAD>']]*self.title_max))\n",
        "            labels.append(lbl)\n",
        "\n",
        "        return (torch.tensor(hist_seq,  dtype=torch.long),        # [H,L]\n",
        "                torch.tensor(cand_seqs, dtype=torch.long),        # [C,L]\n",
        "                torch.tensor(labels,   dtype=torch.float),        # [C]\n",
        "                impr)"
      ],
      "metadata": {
        "id": "ir04iVO71jUm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn_list(batch):\n",
        "    \"\"\"\n",
        "    Devuelve:\n",
        "        hist_batch  : [B, H, L]\n",
        "        cand_batch  : [B, C_max, L]\n",
        "        label_batch : [B, C_max]  (0/1, padded con -1)\n",
        "        mask_batch  : [B, C_max]  (True donde existe candidato)\n",
        "        impr_batch  : list[str]\n",
        "    \"\"\"\n",
        "    hist_list, cand_list, label_list, impr_list = zip(*batch)\n",
        "\n",
        "    # Historial: tamaño fijo\n",
        "    hist_batch = torch.stack(hist_list)             # [B,H,L]\n",
        "\n",
        "    # Candidatos: pad al máximo C del batch\n",
        "    C_max = max(x.size(0) for x in cand_list)\n",
        "    L     = cand_list[0].size(1)\n",
        "    pad_val = 0  # token PAD\n",
        "\n",
        "    cand_pad   = torch.full((len(batch), C_max, L), pad_val, dtype=torch.long)\n",
        "    label_pad  = torch.full((len(batch), C_max),    -1,      dtype=torch.float)\n",
        "    mask_pad   = torch.zeros(len(batch), C_max,     dtype=torch.bool)\n",
        "\n",
        "    for i,(cands, labels) in enumerate(zip(cand_list, label_list)):\n",
        "        C = cands.size(0)\n",
        "        cand_pad[i,:C]  = cands\n",
        "        label_pad[i,:C] = labels\n",
        "        mask_pad[i,:C]  = 1\n",
        "\n",
        "    return (hist_batch.to(device),\n",
        "            cand_pad.to(device),\n",
        "            label_pad.to(device),\n",
        "            mask_pad.to(device),\n",
        "            list(impr_list))\n"
      ],
      "metadata": {
        "id": "euYhosJa1kr3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_hist_title = 50\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "4wqU253z1lsn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MINDListDataset(data, news2idx, word2idx, max_hist_title, max_size_title)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_list)\n",
        "\n",
        "val_dataset = MINDListDataset(val_data, news2idx, word2idx, max_hist_title, max_size_title)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_list)"
      ],
      "metadata": {
        "id": "zlFMx44z1mwm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 300\n",
        "num_heads = 20\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "Lh5_7mMH1nyu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove = True\n",
        "\n",
        "if glove:\n",
        "    embedding_matrix = np.random.normal(scale=0.6, size=(vocab_size, embed_dim))\n",
        "    found = 0\n",
        "    with open(\"glove.6B.300d.txt\", 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.rstrip().split(' ')\n",
        "            word = parts[0]\n",
        "            if word in word2idx:\n",
        "                vec = np.array(parts[1:], dtype=np.float32)\n",
        "                if vec.shape[0] == embed_dim:\n",
        "                    embedding_matrix[word2idx[word]] = vec\n",
        "                    found += 1\n",
        "    print(f'Palabras encontradas en GloVe: {found}/{vocab_size}')\n",
        "    embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float)\n",
        "else:\n",
        "    embedding_matrix = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5iMvqeX1o03",
        "outputId": "941d1745-d27d-4d72-dcc3-ebb0114eaee4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras encontradas en GloVe: 28233/37272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FastformerAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Atención Fastformer (Atención aditiva global) que reemplaza nn.MultiheadAttention.\n",
        "    Opera con entradas de forma (L, B, E) o (B, L, E), realizando la proyección Q, K, V\n",
        "    por separado, obteniendo vectores globales y propagando interacciones por producto\n",
        "    elemento a elemento, según Fastformer (Fastformer: Additive Attention Can Be All You Need).\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, num_heads, dropout=0.0):\n",
        "        super(FastformerAttention, self).__init__()\n",
        "        assert embed_dim % num_heads == 0, \"embed_dim debe ser divisible por num_heads\"\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        # Proyecciones lineales para Q, K, V (similar a multi-cabeza estándar)\n",
        "        self.W_q = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "        self.W_k = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "        self.W_v = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "        # Parámetros de atención aditiva por cabeza (vectores de peso para Q y K)\n",
        "        # Formato (num_heads, head_dim) para aplicar dot-product con cada vector de dimensión head_dim\n",
        "        self.attn_wq = nn.Parameter(torch.Tensor(num_heads, self.head_dim))\n",
        "        self.attn_wk = nn.Parameter(torch.Tensor(num_heads, self.head_dim))\n",
        "        # Capa de salida tras concatenar cabezas\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # Inicialización\n",
        "        nn.init.xavier_uniform_(self.W_q.weight)\n",
        "        nn.init.xavier_uniform_(self.W_k.weight)\n",
        "        nn.init.xavier_uniform_(self.W_v.weight)\n",
        "        nn.init.xavier_uniform_(self.out_proj.weight)\n",
        "        nn.init.zeros_(self.W_q.bias)\n",
        "        nn.init.zeros_(self.W_k.bias)\n",
        "        nn.init.zeros_(self.W_v.bias)\n",
        "        nn.init.zeros_(self.out_proj.bias)\n",
        "        nn.init.xavier_uniform_(self.attn_wq)\n",
        "        nn.init.xavier_uniform_(self.attn_wk)\n",
        "\n",
        "    def forward(self, query, key, value):\n",
        "        \"\"\"\n",
        "        query, key, value: tensores de forma (L, B, E) ó (S, N, E) donde\n",
        "        L=longitud de secuencia, B=batch, E=embed_dim.\n",
        "        Fastformer es simétrico en q=k=v, pero aceptamos tres argumentos para compatibilidad.\n",
        "        \"\"\"\n",
        "        # Permutar para batch-first: [B, L, E]\n",
        "        transpose = False\n",
        "        if query.dim() == 3 and query.shape[0] != query.shape[1]:\n",
        "            # Asumimos forma (L, B, E)\n",
        "            query = query.transpose(0, 1)\n",
        "            key = key.transpose(0, 1)\n",
        "            value = value.transpose(0, 1)\n",
        "            transpose = True\n",
        "        # Proyectar Q, K, V\n",
        "        # Ahora shapes: [B, L, E]\n",
        "        Q = self.W_q(query)   # [B, L, E]\n",
        "        K = self.W_k(key)     # [B, L, E]\n",
        "        V = self.W_v(value)   # [B, L, E]\n",
        "        B, L, E = Q.size()\n",
        "        H = self.num_heads\n",
        "        D = self.head_dim\n",
        "        # Dividir en cabezas: [B, L, H, D]\n",
        "        Q = Q.view(B, L, H, D)\n",
        "        K = K.view(B, L, H, D)\n",
        "        V = V.view(B, L, H, D)\n",
        "        # Reordenar para [B, H, L, D]\n",
        "        Q = Q.permute(0, 2, 1, 3)\n",
        "        K = K.permute(0, 2, 1, 3)\n",
        "        V = V.permute(0, 2, 1, 3)\n",
        "        # =========== Fastformer Steps ===========\n",
        "        # 1) Atención aditiva sobre Q para obtener q_global [B, H, D]\n",
        "        # Calculamos puntuaciones: sum_{j}( w_q[h,j] * Q[...,j] )\n",
        "        # w_q: [H, D], Q: [B, H, L, D]\n",
        "        # Producto elemento a elemento y sumar sobre dimensión D:\n",
        "        # scores_q: [B, H, L]\n",
        "        scores_q = (Q * self.attn_wq.unsqueeze(0).unsqueeze(2)).sum(dim=-1)  # [B, H, L]\n",
        "        alpha = torch.softmax(scores_q, dim=-1)  # [B, H, L]\n",
        "        # Obtener vector q_global: suma ponderada de Q sobre L\n",
        "        # alpha: [B, H, L], Q: [B, H, L, D] -> q_global: [B, H, D]\n",
        "        q_global = torch.einsum('bhl,bhld->bhd', alpha, Q)\n",
        "        # 2) Interactuar q_global con cada K por producto elemento a elemento -> K'\n",
        "        # Extendemos q_global para cada posición L: [B, H, 1, D] * [B, H, L, D] -> [B, H, L, D]\n",
        "        K_prime = q_global.unsqueeze(2) * K  # [B, H, L, D]\n",
        "        # 3) Atención aditiva sobre K_prime para obtener k_global [B, H, D]\n",
        "        scores_k = (K_prime * self.attn_wk.unsqueeze(0).unsqueeze(2)).sum(dim=-1)  # [B, H, L]\n",
        "        beta = torch.softmax(scores_k, dim=-1)  # [B, H, L]\n",
        "        k_global = torch.einsum('bhl,bhld->bhd', beta, K_prime)  # [B, H, D]\n",
        "        # 4) Interactuar k_global con cada V -> V'\n",
        "        V_prime = k_global.unsqueeze(2) * V  # [B, H, L, D]\n",
        "        # Rearmar V' combinando cabezas: [B, H, L, D] -> [B, L, H*D]\n",
        "        V_prime = V_prime.permute(0, 2, 1, 3).contiguous().view(B, L, H * D)  # [B, L, E]\n",
        "        # Capa lineal de salida y agregar Q (residuo)\n",
        "        out = self.out_proj(V_prime)  # [B, L, E]\n",
        "        # Capa residual: sumamos la proyección original de Q antes de dividir cabezas\n",
        "        # Primero reconstruir Q original (bidimensional por cada posición)\n",
        "        Q_orig = Q.permute(0, 2, 1, 3).contiguous().view(B, L, H * D)  # [B, L, E]\n",
        "        out = out + Q_orig\n",
        "        # Opcional: aplicar dropout\n",
        "        out = self.dropout(out)\n",
        "        # Devolver en forma (L, B, E)\n",
        "        if transpose:\n",
        "            out = out.transpose(0, 1).contiguous()\n",
        "        return out"
      ],
      "metadata": {
        "id": "gkNJSt3e1pUY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Codificador de noticias: procesa títulos de noticias (secuencias de tokens)\n",
        "    y produce vectores de noticia. Reemplaza la atención multi-cabeza por FastformerAttention.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, title_max, pretrained_emb=None):\n",
        "        super(NewsEncoder, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.title_max = title_max\n",
        "        # Capa de embedding de palabras\n",
        "        self.word_embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "\n",
        "        if pretrained_emb is not None:\n",
        "            self.word_embedding.weight.data.copy_(pretrained_emb)\n",
        "            self.word_embedding.weight.requires_grad = True  # o False si no quieres fine-tune\n",
        "\n",
        "        # Capa convolucional 1D para extraer características locales de palabras (opcional, similar a arquitectura original)\n",
        "        # Usamos múltiples filtros 1xD para captar n-gramas de tamaño 3 por ejemplo\n",
        "        self.conv = nn.Conv1d(in_channels=embed_dim, out_channels=embed_dim, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        # Atención Fastformer sobre la secuencia de características de palabras\n",
        "        self.self_attn = FastformerAttention(embed_dim, num_heads, dropout=0.1)\n",
        "        # Atención aditiva para agregar las palabras importantes en el título\n",
        "        self.attn_vector = nn.Linear(embed_dim, 1)  # para puntuación de cada palabra\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: tensor de tokens de noticias con forma [B, title_max].\n",
        "        Devuelve: vectores de noticias de forma [B, embed_dim].\n",
        "        \"\"\"\n",
        "        # Embedding y extracción de características locales\n",
        "        # Palabras: [B, title_max, E] -> conv espera [B, E, title_max]\n",
        "        emb = self.word_embedding(x)            # [B, L, E]\n",
        "        emb = emb.transpose(1, 2)               # [B, E, L]\n",
        "        conv_out = self.relu(self.conv(emb))    # [B, E, L]\n",
        "        conv_out = conv_out.transpose(1, 2)     # [B, L, E]\n",
        "        # Atención Fastformer (auto-atención) entre las posiciones de palabras\n",
        "        # FastformerAttention espera (L, B, E) o (B, L, E); adaptamos:\n",
        "        conv_out_trans = conv_out.transpose(0, 1).contiguous()  # [L, B, E]\n",
        "        attn_out = self.self_attn(conv_out_trans, conv_out_trans, conv_out_trans)  # [L, B, E]\n",
        "        attn_out = attn_out.transpose(0, 1)  # [B, L, E]\n",
        "        # Atención aditiva para obtener vector final de noticia\n",
        "        # Calcular puntuación de importancia para cada palabra\n",
        "        scores = self.attn_vector(attn_out).squeeze(-1)  # [B, L]\n",
        "        weights = self.softmax(scores)                    # [B, L]\n",
        "        news_vector = torch.bmm(weights.unsqueeze(1), attn_out).squeeze(1)  # [B, E]\n",
        "        return news_vector  # [B, embed_dim]\n",
        "\n",
        "class UserEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Codificador de usuario: agrega vectores de noticias historiales usando Fastformer.\n",
        "    Toma un historial de noticias y devuelve un vector de usuario.\n",
        "    \"\"\"\n",
        "    def __init__(self, news_encoder, embed_dim, num_heads, hist_max):\n",
        "        super(UserEncoder, self).__init__()\n",
        "        self.news_encoder = news_encoder  # instancia de NewsEncoder para codificar cada noticia\n",
        "        self.hist_max = hist_max\n",
        "        # Atención Fastformer sobre la secuencia de vectores de noticia del historial\n",
        "        self.self_attn = FastformerAttention(embed_dim, num_heads, dropout=0.1)\n",
        "        # Atención aditiva para agregar las noticias más relevantes del historial\n",
        "        self.attn_vector = nn.Linear(embed_dim, 1)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, hist_x):\n",
        "        \"\"\"\n",
        "        hist_x: tensor de tokens de noticias de historial con forma [B, hist_max, title_max].\n",
        "        Devuelve: vector de usuario de forma [B, embed_dim].\n",
        "        \"\"\"\n",
        "        B, H, L = hist_x.size()\n",
        "        # Codificar cada noticia en el historial\n",
        "        hist_x_flat = hist_x.view(B * H, L)                  # [B*H, title_max]\n",
        "        news_vectors = self.news_encoder(hist_x_flat)        # [B*H, embed_dim]\n",
        "        news_vectors = news_vectors.view(B, H, -1)           # [B, hist_max, embed_dim]\n",
        "        # Atención Fastformer sobre las noticias del historial\n",
        "        nv_trans = news_vectors.transpose(0, 1).contiguous() # [H, B, E]\n",
        "        attn_out = self.self_attn(nv_trans, nv_trans, nv_trans)  # [H, B, E]\n",
        "        attn_out = attn_out.transpose(0, 1)                  # [B, H, E]\n",
        "        # Atención aditiva para agregar vectores de noticias importantes\n",
        "        scores = self.attn_vector(attn_out).squeeze(-1)      # [B, H]\n",
        "        weights = self.softmax(scores)                       # [B, H]\n",
        "        user_vector = torch.bmm(weights.unsqueeze(1), attn_out).squeeze(1)  # [B, E]\n",
        "        return user_vector  # [B, embed_dim]"
      ],
      "metadata": {
        "id": "JPmn3pVg11NZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FastformerNRMS(nn.Module):\n",
        "    \"\"\"\n",
        "    Modelo NRMS modificado con Fastformer.\n",
        "    Mantiene la misma interfaz: forward(hist_tensor, cand_tensor).\n",
        "    hist_tensor: [B, hist_max, title_max], cand_tensor: [B, cand_count, title_max].\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, title_max, hist_max, pretrained_emb=None):\n",
        "        super(FastformerNRMS, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.title_max = title_max\n",
        "        self.hist_max = hist_max\n",
        "        # News encoder y user encoder con Fastformer\n",
        "        self.news_encoder = NewsEncoder(vocab_size, embed_dim, num_heads, title_max, pretrained_emb)\n",
        "        self.user_encoder = UserEncoder(self.news_encoder, embed_dim, num_heads, hist_max)\n",
        "        # (Opcional) proyección final o dropout\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, hist_tensor, cand_tensor, mask=None):\n",
        "        \"\"\"\n",
        "        hist_tensor : [B, hist_max, title_max]\n",
        "        cand_tensor : [B, C,       title_max]\n",
        "        mask        : [B, C]  (bool) – True donde el candidato existe\n",
        "        \"\"\"\n",
        "        B, H, L = hist_tensor.size()\n",
        "        _, C, _ = cand_tensor.size()\n",
        "        # Codificar usuario\n",
        "        user_vector = self.user_encoder(hist_tensor)            # [B, E]\n",
        "        # Codificar candidatos (aplicar NewsEncoder a cada candidato)\n",
        "        cand_flat = cand_tensor.view(B * C, L)                  # [B*C, title_max]\n",
        "        cand_vecs = self.news_encoder(cand_flat)               # [B*C, E]\n",
        "        cand_vecs = cand_vecs.view(B, C, -1)                   # [B, cand_count, E]\n",
        "        # Calcular similaridad (producto punto usuario con cada candidato)\n",
        "        # Expandir user_vector para combinar con candidatos\n",
        "\n",
        "        cand_vecs = self.dropout(cand_vecs)\n",
        "        user_vector = self.dropout(user_vector)\n",
        "\n",
        "        user_exp = user_vector.unsqueeze(1)                    # [B, 1, E]\n",
        "        logits = torch.sum(cand_vecs * user_exp, dim=-1)       # [B, cand_count]\n",
        "\n",
        "        if mask is not None:\n",
        "            logits = logits.masked_fill(~mask, -1e9)             # -∞ donde no hay candidato\n",
        "\n",
        "        return logits                                            # [B,C]"
      ],
      "metadata": {
        "id": "TyZkcEl512j7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastformerNRMS(vocab_size, embed_dim, num_heads, max_size_title, max_hist_title,\n",
        "             pretrained_emb=embedding_matrix.to(device) if embedding_matrix is not None else None)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ytcEQxLA14d_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def ndcg_score(labels, scores, k=5):\n",
        "    order = np.argsort(scores)[::-1]\n",
        "    labels = np.array(labels)\n",
        "    dcg = 0.0\n",
        "    for i in range(min(k, len(labels))):\n",
        "        rel = labels[order[i]]\n",
        "        dcg += (2**rel - 1) / np.log2(i+2)\n",
        "    ideal = np.sort(labels)[::-1]\n",
        "    idcg = 0.0\n",
        "    for i in range(min(k, int(np.sum(labels)))):\n",
        "        idcg += 1.0 / np.log2(i+2)\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "def mrr_score(labels, scores):\n",
        "    order = np.argsort(scores)[::-1]\n",
        "    labels = np.array(labels)[order]\n",
        "    for rank, label in enumerate(labels, start=1):\n",
        "        if label == 1:\n",
        "            return 1.0 / rank\n",
        "    return 0.0"
      ],
      "metadata": {
        "id": "_tmaqomD2tuG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3"
      ],
      "metadata": {
        "id": "q64WVk6a2xjO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_ndcg5 = 0.0\n",
        "best_model_state = None\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for hist_batch, cand_batch, label_batch, mask_batch, _ in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(hist_batch, cand_batch, mask_batch)\n",
        "        target = label_batch.argmax(dim=1)        # [B]\n",
        "        loss = criterion(logits, target)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch} - Pérdida promedio: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluación en validación\n",
        "    if val_loader is None:\n",
        "        continue\n",
        "\n",
        "    model.eval()\n",
        "    ndcg5_list, ndcg10_list, mrr_list, auc_list = [], [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for hist_batch, cand_batch, label_batch, mask_batch, impr_batch in val_loader:\n",
        "            logits  = model(hist_batch, cand_batch, mask_batch)  # [B,C]\n",
        "            scores  = logits.cpu().numpy()\n",
        "            labels  = label_batch.cpu().numpy()\n",
        "            masks   = mask_batch.cpu().numpy()\n",
        "\n",
        "            for s, l, m in zip(scores, labels, masks):\n",
        "                # recortar a candidatos reales\n",
        "                s = s[m]        # (C_real,)\n",
        "                l = l[m]        # (C_real,)\n",
        "\n",
        "                ndcg5_list .append(ndcg_score(l, s, k=5))\n",
        "                ndcg10_list.append(ndcg_score(l, s, k=10))\n",
        "                mrr_list  .append(mrr_score(l, s))\n",
        "                if l.max() > 0 and l.min() == 0:     # al menos 1 pos y 1 neg\n",
        "                    auc_list.append(roc_auc_score(l, s))\n",
        "\n",
        "    ndcg5  = np.mean(ndcg5_list)\n",
        "    ndcg10 = np.mean(ndcg10_list)\n",
        "    mrr    = np.mean(mrr_list)\n",
        "    auc    = np.mean(auc_list) if auc_list else 0.0\n",
        "\n",
        "    if ndcg5 > best_ndcg5:\n",
        "        best_ndcg5 = ndcg5\n",
        "        best_model_state = model.state_dict()\n",
        "        print(f\"» Nuevo mejor modelo guardado (nDCG@5 = {ndcg5:.4f})\")\n",
        "\n",
        "    print(f\"Validación – AUC: {auc:.4f} | MRR: {mrr:.4f} | \"\n",
        "          f\"nDCG@5: {ndcg5:.4f} | nDCG@10: {ndcg10:.4f}\")\n",
        "\n",
        "if best_model_state is not None:\n",
        "    torch.save(best_model_state, \"nrms_fastformer_best.pt\")\n",
        "    print(\"Modelo con mejor nDCG@5 guardado en nrms_fastformer_best.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duLvr7fm2yjP",
        "outputId": "5d926e2f-d0cc-4fe0-dd7a-2c2dceb826d2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/3: 100%|██████████| 3960/3960 [16:10<00:00,  4.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Pérdida promedio: 2.8049\n",
            "» Nuevo mejor modelo guardado (nDCG@5 = 0.2858)\n",
            "Validación – AUC: 0.6276 | MRR: 0.3106 | nDCG@5: 0.2858 | nDCG@10: 0.3481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 3960/3960 [16:12<00:00,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Pérdida promedio: 65.8642\n",
            "» Nuevo mejor modelo guardado (nDCG@5 = 0.3024)\n",
            "Validación – AUC: 0.6391 | MRR: 0.3287 | nDCG@5: 0.3024 | nDCG@10: 0.3633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 3960/3960 [16:11<00:00,  4.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Pérdida promedio: 2.9286\n",
            "Validación – AUC: 0.6355 | MRR: 0.3252 | nDCG@5: 0.2988 | nDCG@10: 0.3612\n",
            "Modelo con mejor nDCG@5 guardado en nrms_fastformer_best.pt\n"
          ]
        }
      ]
    }
  ]
}