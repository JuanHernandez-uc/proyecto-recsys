{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_hAHBsrYo_b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_behaviors = pd.read_csv(\"beh.tsv\", sep=\"\\t\", names=['ImpressionID', 'UserID', 'Time', 'History', 'Impressions'])\n",
        "df_news = pd.read_csv(\"news.tsv\", sep=\"\\t\", names=['NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'TitleEntities', 'AbstractEntities'])\n",
        "\n",
        "df_behaviors[\"Time\"] = pd.to_datetime(df_behaviors[\"Time\"])\n",
        "cutoff = pd.to_datetime(\"2019-11-14\")\n",
        "\n",
        "behavior_train = df_behaviors[df_behaviors[\"Time\"] < cutoff].copy()\n",
        "behavior_val = df_behaviors[df_behaviors[\"Time\"] >= cutoff].copy()\n"
      ],
      "metadata": {
        "id": "GT33fJRIY8eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    tokens = re.findall(r\"[\\w']+\", text.lower())\n",
        "    return tokens\n",
        "\n",
        "longitudes = df_news[\"Title\"].dropna().apply(lambda x: len(x.split()))\n",
        "cantidad_menor_20 = (longitudes < 20).sum()\n",
        "total = len(longitudes)\n",
        "print(f\"Titles with less than 20 words: {cantidad_menor_20} of {total} ({cantidad_menor_20 / total:.2%})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYdvjHU_ZW9O",
        "outputId": "c55951e1-8bf0-43ed-8133-3587eda5b876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Titles with less than 20 words: 23339 of 23701 (98.47%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
        "idx = 2\n",
        "news2idx = {}\n",
        "max_size_title = 20\n",
        "\n",
        "\n",
        "category2idx = {'<UNK>': 0}\n",
        "subcategory2idx = {'<UNK>': 0}\n",
        "cat_idx = 1\n",
        "subcat_idx = 1\n",
        "\n",
        "user2idx = {'<UNK>': 0}\n",
        "user_idx = 1"
      ],
      "metadata": {
        "id": "7XY7JyhAZh3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in tqdm(df_news.iterrows(), total=df_news.shape[0]):\n",
        "    news_id = row[\"NewsID\"]\n",
        "    title = row[\"Title\"]\n",
        "    category = row[\"Category\"] if not pd.isna(row[\"Category\"]) else \"<UNK>\"\n",
        "    subcategory = row[\"SubCategory\"] if not pd.isna(row[\"SubCategory\"]) else \"<UNK>\"\n",
        "\n",
        "    # Process title tokens\n",
        "    tokens = [] if pd.isna(title) else tokenize(title)\n",
        "    token_idxs = []\n",
        "    for w in tokens[:max_size_title]:\n",
        "        if w not in word2idx:\n",
        "            word2idx[w] = idx\n",
        "            idx += 1\n",
        "        token_idxs.append(word2idx.get(w, word2idx['<UNK>']))\n",
        "\n",
        "    # Pad title if shorter than max_size_title\n",
        "    if len(token_idxs) < max_size_title:\n",
        "        token_idxs += [word2idx['<PAD>']] * (max_size_title - len(token_idxs))\n",
        "\n",
        "    # Process categories\n",
        "    if category not in category2idx:\n",
        "        category2idx[category] = cat_idx\n",
        "        cat_idx += 1\n",
        "    if subcategory not in subcategory2idx:\n",
        "        subcategory2idx[subcategory] = subcat_idx\n",
        "        subcat_idx += 1\n",
        "\n",
        "    news2idx[news_id] = {\n",
        "        'title': token_idxs,\n",
        "        'category': category2idx[category],\n",
        "        'subcategory': subcategory2idx[subcategory]\n",
        "    }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLoEmzjMZl9n",
        "outputId": "6f4f77d3-918b-4e07-e855-e5903a5cfa88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23701/23701 [00:02<00:00, 9644.96it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in tqdm(behavior_train.iterrows(), total=behavior_train.shape[0]):\n",
        "    user_id = row['UserID']\n",
        "    if user_id not in user2idx:\n",
        "        user2idx[user_id] = user_idx\n",
        "        user_idx += 1\n",
        "\n",
        "for _, row in tqdm(behavior_val.iterrows(), total=behavior_val.shape[0]):\n",
        "    user_id = row['UserID']\n",
        "    if user_id not in user2idx:\n",
        "        user2idx[user_id] = user_idx\n",
        "        user_idx += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN0xSNUJZrrM",
        "outputId": "edad98e4-89d5-4535-caa8-53ee9ae619dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12664/12664 [00:00<00:00, 15358.73it/s]\n",
            "100%|██████████| 3047/3047 [00:00<00:00, 9610.30it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word2idx)\n",
        "num_categories = len(category2idx)\n",
        "num_subcategories = len(subcategory2idx)\n",
        "num_users = len(user2idx)\n",
        "\n",
        "print(f'Vocabulary: {vocab_size} words')\n",
        "print(f'Categories: {num_categories}')\n",
        "print(f'Subcategories: {num_subcategories}')\n",
        "print(f'Users: {num_users}')\n",
        "\n",
        "data = []\n",
        "for _, row in tqdm(behavior_train.iterrows(), total=behavior_train.shape[0]):\n",
        "    user_id = row['UserID']\n",
        "    hist_str = row['History']\n",
        "    hist_ids = [] if pd.isna(hist_str) else [nid for nid in hist_str.split() if nid]\n",
        "    impr = row['ImpressionID']\n",
        "    imps = [] if pd.isna(row['Impressions']) else row['Impressions'].split()\n",
        "\n",
        "    for imp in imps:\n",
        "        if len(imp) == 0:\n",
        "            continue\n",
        "        parts = imp.split('-')\n",
        "        if len(parts) != 2:\n",
        "            continue\n",
        "        news_id, click = parts[0], parts[1]\n",
        "        label = int(click)\n",
        "        data.append((impr, user_id, hist_ids, news_id, label))\n",
        "\n",
        "data = data[:460000]\n",
        "print(f'Total interaction examples: {len(data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33dELLg5ZviU",
        "outputId": "2abfb8d2-70e3-4b09-edb2-029db2f31bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: 25906 words\n",
            "Categories: 18\n",
            "Subcategories: 239\n",
            "Users: 5001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12664/12664 [00:03<00:00, 3173.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total interaction examples: 452619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = []\n",
        "for _, row in tqdm(behavior_val.iterrows(), total=behavior_val.shape[0]):\n",
        "    user_id = row['UserID']\n",
        "    hist_str = row['History']\n",
        "    hist_ids = [] if pd.isna(hist_str) else [nid for nid in hist_str.split() if nid]\n",
        "    impr = row['ImpressionID']\n",
        "    imps = row['Impressions'].split()\n",
        "\n",
        "    for imp in imps:\n",
        "        if len(imp) == 0:\n",
        "            continue\n",
        "        parts = imp.split('-')\n",
        "        if len(parts) != 2:\n",
        "            continue\n",
        "        news_id, click = parts[0], parts[1]\n",
        "        val_data.append((impr, user_id, hist_ids, news_id, int(click)))\n",
        "\n",
        "val_data = val_data[:120000]\n",
        "print(f'Total validation examples: {len(val_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke57UanTZzYJ",
        "outputId": "6517fb32-a335-4579-d12a-1b3b956a24dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3047/3047 [00:00<00:00, 3594.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total validation examples: 120000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MINDDatasetLSTUR(Dataset):\n",
        "    def __init__(self, interactions, news2idx, word2idx, user2idx, hist_max, title_max):\n",
        "        self.interactions = interactions\n",
        "        self.news2idx = news2idx\n",
        "        self.word2idx = word2idx\n",
        "        self.user2idx = user2idx\n",
        "        self.hist_max = hist_max\n",
        "        self.title_max = title_max\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.interactions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        impr, user_id, hist_ids, cand_id, label = self.interactions[idx]\n",
        "\n",
        "        # Get user ID\n",
        "        user_idx = self.user2idx.get(user_id, self.user2idx['<UNK>'])\n",
        "\n",
        "        if len(hist_ids) > self.hist_max:\n",
        "            hist_ids = hist_ids[-self.hist_max:]\n",
        "\n",
        "        hist_seq = []\n",
        "        for nid in hist_ids:\n",
        "            if nid in self.news2idx:\n",
        "                seq = self.news2idx[nid]['title']\n",
        "            else:\n",
        "                seq = [self.word2idx['<PAD>']] * self.title_max\n",
        "            hist_seq.append(seq)\n",
        "\n",
        "        if len(hist_seq) < self.hist_max:\n",
        "            pad_seq = [self.word2idx['<PAD>']] * self.title_max\n",
        "            for _ in range(self.hist_max - len(hist_seq)):\n",
        "                hist_seq.insert(0, pad_seq)\n",
        "\n",
        "        if cand_id in self.news2idx:\n",
        "            cand_seq = self.news2idx[cand_id]['title']\n",
        "            cand_cat = self.news2idx[cand_id]['category']\n",
        "            cand_subcat = self.news2idx[cand_id]['subcategory']\n",
        "        else:\n",
        "            cand_seq = [self.word2idx['<PAD>']] * self.title_max\n",
        "            cand_cat = 0\n",
        "            cand_subcat = 0\n",
        "\n",
        "        # Convert to tensors\n",
        "        hist_tensor = torch.tensor(hist_seq, dtype=torch.long)\n",
        "        cand_tensor = torch.tensor(cand_seq, dtype=torch.long)\n",
        "        cand_cat_tensor = torch.tensor(cand_cat, dtype=torch.long)\n",
        "        cand_subcat_tensor = torch.tensor(cand_subcat, dtype=torch.long)\n",
        "        user_tensor = torch.tensor(user_idx, dtype=torch.long)\n",
        "        label_tensor = torch.tensor(label, dtype=torch.float)\n",
        "\n",
        "        return hist_tensor, cand_tensor, cand_cat_tensor, cand_subcat_tensor, user_tensor, label_tensor, impr\n",
        "\n",
        "def collate_fn_lstur(batch):\n",
        "    hist_list, cand_list, cand_cat_list, cand_subcat_list, user_list, label_list, impr_list = zip(*batch)\n",
        "\n",
        "    hist_batch = torch.stack(hist_list)\n",
        "    cand_batch = torch.stack(cand_list)\n",
        "    cand_cat_batch = torch.stack(cand_cat_list)\n",
        "    cand_subcat_batch = torch.stack(cand_subcat_list)\n",
        "    user_batch = torch.stack(user_list)\n",
        "    label_batch = torch.stack(label_list).view(-1, 1)\n",
        "    impr_batch = list(impr_list)\n",
        "\n",
        "    return (hist_batch.to(device), cand_batch.to(device), cand_cat_batch.to(device),\n",
        "            cand_subcat_batch.to(device), user_batch.to(device), label_batch.to(device), impr_batch)\n"
      ],
      "metadata": {
        "id": "xoEsbLWvZ29o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionPooling(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(AttentionPooling, self).__init__()\n",
        "        self.att_fc1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.att_fc2 = nn.Linear(hidden_size, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        bz = x.shape[0]\n",
        "        e = self.att_fc1(x)\n",
        "        e = self.tanh(e)\n",
        "        alpha = self.att_fc2(e)\n",
        "        alpha = torch.exp(alpha)\n",
        "        if attn_mask is not None:\n",
        "            alpha = alpha * attn_mask.unsqueeze(2)\n",
        "        alpha = alpha / (torch.sum(alpha, dim=1, keepdim=True) + 1e-8)\n",
        "        x = torch.bmm(x.permute(0, 2, 1), alpha)\n",
        "        x = torch.reshape(x, (bz, -1))\n",
        "        return x\n",
        "\n",
        "class NewsEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, num_categories, num_subcategories, embed_dim, num_filters=100, window_size=3):\n",
        "        super(NewsEncoder, self).__init__()\n",
        "        self.word_embed = nn.Embedding(vocab_size, embed_dim, padding_idx=word2idx['<PAD>'])\n",
        "        self.category_embed = nn.Embedding(num_categories, embed_dim)\n",
        "        self.subcategory_embed = nn.Embedding(num_subcategories, embed_dim)\n",
        "\n",
        "        self.cnn = nn.Conv1d(embed_dim, num_filters, window_size, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "        self.attention = AttentionPooling(num_filters)\n",
        "\n",
        "        # Final projection\n",
        "        self.final_dim = num_filters + embed_dim + embed_dim\n",
        "\n",
        "    def forward(self, title, category, subcategory):\n",
        "        # Title encoding\n",
        "        title_emb = self.word_embed(title)\n",
        "        title_emb_t = title_emb.transpose(1, 2)\n",
        "        title_cnn = self.relu(self.cnn(title_emb_t))\n",
        "        title_cnn_t = title_cnn.transpose(1, 2)\n",
        "\n",
        "        mask = title.bool().float()\n",
        "        title_vec = self.attention(title_cnn_t, mask)\n",
        "\n",
        "        cat_vec = self.category_embed(category)\n",
        "        subcat_vec = self.subcategory_embed(subcategory)\n",
        "\n",
        "        news_vec = torch.cat([title_vec, cat_vec, subcat_vec], dim=1)\n",
        "        return news_vec"
      ],
      "metadata": {
        "id": "hR4_k4gbZ5sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LongTermUserRepresentation(nn.Module):\n",
        "    def __init__(self, num_users, embed_dim):\n",
        "        super(LongTermUserRepresentation, self).__init__()\n",
        "        self.user_embed = nn.Embedding(num_users, embed_dim)\n",
        "\n",
        "    def forward(self, user_ids, mask_prob=0.0):\n",
        "        user_vec = self.user_embed(user_ids)\n",
        "\n",
        "        if self.training and mask_prob > 0:\n",
        "            mask = torch.bernoulli(torch.full_like(user_vec[:, 0:1], 1 - mask_prob))\n",
        "            user_vec = user_vec * mask\n",
        "\n",
        "        return user_vec\n",
        "\n",
        "class ShortTermUserRepresentation(nn.Module):\n",
        "    def __init__(self, news_dim, hidden_dim):\n",
        "        super(ShortTermUserRepresentation, self).__init__()\n",
        "        self.gru = nn.GRU(news_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, news_sequence, init_hidden=None):\n",
        "\n",
        "        output, hidden = self.gru(news_sequence, init_hidden)\n",
        "        return hidden.squeeze(0)"
      ],
      "metadata": {
        "id": "sbvGNRa6Z8NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTUR(nn.Module):\n",
        "    def __init__(self, vocab_size, num_categories, num_subcategories, num_users,\n",
        "                 embed_dim, hidden_dim, mask_prob=0.5, combination_method='concatenation'):\n",
        "        super(LSTUR, self).__init__()\n",
        "        self.news_encoder = NewsEncoder(vocab_size, num_categories, num_subcategories, embed_dim)\n",
        "        self.long_term = LongTermUserRepresentation(num_users, hidden_dim)\n",
        "        self.short_term = ShortTermUserRepresentation(self.news_encoder.final_dim, hidden_dim)\n",
        "        self.mask_prob = mask_prob\n",
        "        self.combination_method = combination_method\n",
        "\n",
        "        if combination_method == 'concatenation':\n",
        "            self.final_dim = hidden_dim * 2\n",
        "        else:\n",
        "            self.final_dim = hidden_dim\n",
        "\n",
        "    def forward(self, hist_titles, hist_categories, hist_subcategories,\n",
        "                cand_title, cand_category, cand_subcategory, user_ids):\n",
        "        batch_size, hist_len, title_len = hist_titles.shape\n",
        "\n",
        "        # Encode historical news\n",
        "        hist_flat_titles = hist_titles.view(-1, title_len)\n",
        "        hist_flat_cats = hist_categories.view(-1) if hist_categories.dim() > 1 else hist_categories.repeat(batch_size * hist_len)\n",
        "        hist_flat_subcats = hist_subcategories.view(-1) if hist_subcategories.dim() > 1 else hist_subcategories.repeat(batch_size * hist_len)\n",
        "\n",
        "        hist_cats = torch.zeros_like(hist_flat_cats)\n",
        "        hist_subcats = torch.zeros_like(hist_flat_subcats)\n",
        "\n",
        "        hist_news_vecs = self.news_encoder(hist_flat_titles, hist_cats, hist_subcats)\n",
        "        hist_news_vecs = hist_news_vecs.view(batch_size, hist_len, -1)\n",
        "\n",
        "        long_term_vec = self.long_term(user_ids, self.mask_prob)\n",
        "\n",
        "        # Short-term user representation\n",
        "        if self.combination_method == 'initialization':\n",
        "            init_hidden = long_term_vec.unsqueeze(0)\n",
        "            short_term_vec = self.short_term(hist_news_vecs, init_hidden)\n",
        "            user_vec = short_term_vec\n",
        "        else:\n",
        "            short_term_vec = self.short_term(hist_news_vecs)\n",
        "            user_vec = torch.cat([long_term_vec, short_term_vec], dim=1)\n",
        "\n",
        "        # Encode candidate news\n",
        "        cand_vec = self.news_encoder(cand_title, cand_category, cand_subcategory)\n",
        "\n",
        "        # Compute click score\n",
        "        score = torch.sum(user_vec * cand_vec[:, :self.final_dim], dim=1)\n",
        "        return score"
      ],
      "metadata": {
        "id": "54ox_UZwaK6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_hist_title = 50\n",
        "batch_size = 128\n",
        "embed_dim = 300\n",
        "hidden_dim = 300\n",
        "lr = 0.001\n",
        "epochs = 3\n",
        "mask_prob = 0.5\n",
        "\n",
        "train_dataset = MINDDatasetLSTUR(data, news2idx, word2idx, user2idx, max_hist_title, max_size_title)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_lstur)\n",
        "\n",
        "val_dataset = MINDDatasetLSTUR(val_data, news2idx, word2idx, user2idx, max_hist_title, max_size_title)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_lstur)\n",
        "\n",
        "# Initialize model\n",
        "model = LSTUR(vocab_size, num_categories, num_subcategories, num_users,\n",
        "              embed_dim, hidden_dim, mask_prob, combination_method='concatenation')\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "T41guGAkaM7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def ndcg_score(labels, scores, k=5):\n",
        "    order = np.argsort(scores)[::-1]\n",
        "    labels = np.array(labels)\n",
        "    dcg = 0.0\n",
        "    for i in range(min(k, len(labels))):\n",
        "        rel = labels[order[i]]\n",
        "        dcg += (2**rel - 1) / np.log2(i+2)\n",
        "    ideal = np.sort(labels)[::-1]\n",
        "    idcg = 0.0\n",
        "    for i in range(min(k, int(np.sum(labels)))):\n",
        "        idcg += 1.0 / np.log2(i+2)\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "def mrr_score(labels, scores):\n",
        "    order = np.argsort(scores)[::-1]\n",
        "    labels = np.array(labels)[order]\n",
        "    for rank, label in enumerate(labels, start=1):\n",
        "        if label == 1:\n",
        "            return 1.0 / rank\n",
        "    return 0.0"
      ],
      "metadata": {
        "id": "PLQIcGH8aTAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def ndcg_score(labels, scores, k=5):\n",
        "    order = np.argsort(scores)[::-1]\n",
        "    labels = np.array(labels)\n",
        "    dcg = 0.0\n",
        "    for i in range(min(k, len(labels))):\n",
        "        rel = labels[order[i]]\n",
        "        dcg += (2**rel - 1) / np.log2(i+2)\n",
        "    ideal = np.sort(labels)[::-1]\n",
        "    idcg = 0.0\n",
        "    for i in range(min(k, int(np.sum(labels)))):\n",
        "        idcg += 1.0 / np.log2(i+2)\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "def mrr_score(labels, scores):\n",
        "    order = np.argsort(scores)[::-1]\n",
        "    labels = np.array(labels)[order]\n",
        "    for rank, label in enumerate(labels, start=1):\n",
        "        if label == 1:\n",
        "            return 1.0 / rank\n",
        "    return 0.0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch_data in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
        "        hist_batch, cand_batch, cand_cat_batch, cand_subcat_batch, user_batch, label_batch, _ = batch_data\n",
        "\n",
        "        # Create dummy category/subcategory tensors for historical news (simplified)\n",
        "        hist_cat_batch = torch.zeros(hist_batch.shape[0], hist_batch.shape[1], dtype=torch.long, device=device)\n",
        "        hist_subcat_batch = torch.zeros(hist_batch.shape[0], hist_batch.shape[1], dtype=torch.long, device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(hist_batch, hist_cat_batch, hist_subcat_batch,\n",
        "                      cand_batch, cand_cat_batch, cand_subcat_batch, user_batch)\n",
        "        loss = criterion(scores, label_batch.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch} - Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    if val_loader is not None:\n",
        "        model.eval()\n",
        "        all_preds = {}\n",
        "        all_scores_flat = []\n",
        "        all_labels_flat = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_data in val_loader:\n",
        "                hist_batch, cand_batch, cand_cat_batch, cand_subcat_batch, user_batch, label_batch, impr_batch = batch_data\n",
        "\n",
        "                hist_cat_batch = torch.zeros(hist_batch.shape[0], hist_batch.shape[1], dtype=torch.long, device=device)\n",
        "                hist_subcat_batch = torch.zeros(hist_batch.shape[0], hist_batch.shape[1], dtype=torch.long, device=device)\n",
        "\n",
        "                scores = model(hist_batch, hist_cat_batch, hist_subcat_batch,\n",
        "                              cand_batch, cand_cat_batch, cand_subcat_batch, user_batch).cpu().numpy()\n",
        "                labels = label_batch.cpu().numpy().flatten()\n",
        "\n",
        "                all_scores_flat.extend(scores)\n",
        "                all_labels_flat.extend(labels)\n",
        "\n",
        "                for impr_id, s, l in zip(impr_batch, scores, labels):\n",
        "                    all_preds.setdefault(impr_id, []).append((s, l))\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        correct, total = 0, 0\n",
        "        ndcg5_list = []\n",
        "        ndcg10_list = []\n",
        "        mrr_list = []\n",
        "\n",
        "        for impr_id, recs in all_preds.items():\n",
        "            scores = [s for (s, l) in recs]\n",
        "            labels = [l for (s, l) in recs]\n",
        "            preds_bin = [1 if s >= 0.0 else 0 for s in scores]\n",
        "            correct += sum(int(p == l) for p, l in zip(preds_bin, labels))\n",
        "            total += len(labels)\n",
        "            ndcg5_list.append(ndcg_score(labels, scores, k=5))\n",
        "            ndcg10_list.append(ndcg_score(labels, scores, k=10))\n",
        "            mrr_list.append(mrr_score(labels, scores))\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        acc = correct / total if total > 0 else 0\n",
        "        auc = roc_auc_score(all_labels_flat, all_scores_flat) if len(set(all_labels_flat)) > 1 else 0\n",
        "        ndcg5 = np.mean(ndcg5_list) if ndcg5_list else 0\n",
        "        ndcg10 = np.mean(ndcg10_list) if ndcg10_list else 0\n",
        "        mrr = np.mean(mrr_list) if mrr_list else 0\n",
        "\n",
        "        print(f\"Validation - Accuracy: {acc:.4f}, AUC: {auc:.4f}, MRR: {mrr:.4f}, nDCG@5: {ndcg5:.4f}, nDCG@10: {ndcg10:.4f}\")\n",
        "\n",
        "print(\"Training completed!\")"
      ],
      "metadata": {
        "id": "3q8cKgVqqKNv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}