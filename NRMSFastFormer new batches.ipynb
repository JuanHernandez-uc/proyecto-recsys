{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRn7tAtvznt-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import defaultdict\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_behaviors = pd.read_csv(\"behaviors.tsv\", sep=\"\\t\", names=['ImpressionID', 'UserID', 'Time', 'History', 'Impressions'])\n",
        "df_news = pd.read_csv(\"news.tsv\", sep=\"\\t\", names=['NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'TitleEntities', 'AbstractEntities'])"
      ],
      "metadata": {
        "id": "1tPZIFG41D58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_behaviors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-d0mvuo1Vn_",
        "outputId": "3b49174f-80dc-4b41-8370-b5e8a7cb5651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156965, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_behaviors[\"Time\"] = pd.to_datetime(df_behaviors[\"Time\"])\n",
        "cutoff = pd.to_datetime(\"2019-11-14\")\n",
        "\n",
        "behavior_train = df_behaviors[df_behaviors[\"Time\"] < cutoff].copy()\n",
        "behavior_val   = df_behaviors[df_behaviors[\"Time\"] >= cutoff].copy()"
      ],
      "metadata": {
        "id": "65S_yx1t1Wln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Usando dispositivo: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TW6Z1YS1XjO",
        "outputId": "d482dc60-1d70-47b9-cded-8bf3489bf193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    tokens = re.findall(r\"[\\w']+\", text.lower())\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "H50xqCYK1YhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "longitudes = df_news[\"Title\"].dropna().apply(lambda x: len(x.split()))\n",
        "cantidad_menor_20 = (longitudes < 20).sum()\n",
        "total = len(longitudes)\n",
        "\n",
        "print(f\"Títulos con menos de 20 palabras: {cantidad_menor_20} de {total} ({cantidad_menor_20 / total:.2%})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE9Fzw-J1ZZO",
        "outputId": "61fa6d19-e4d4-456a-fc2c-050714ead421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Títulos con menos de 20 palabras: 50633 de 51282 (98.73%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
        "idx = 2 # Por <UNK> y <PAD>\n",
        "news2idx = {}  # Mapeo: news_id -> lista de índices de palabras (padded/trunc)\n",
        "max_size_title = 20"
      ],
      "metadata": {
        "id": "sWUBzwkT1ahW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in tqdm(df_news.iterrows(), total=df_news.shape[0]):\n",
        "    news_id = row[\"NewsID\"]\n",
        "    title = row[\"Title\"]\n",
        "    tokens = [] if pd.isna(title) else tokenize(title)\n",
        "    token_idxs = []\n",
        "    for w in tokens[:max_size_title]:  # truncar título largo\n",
        "        if w not in word2idx:\n",
        "            word2idx[w] = idx\n",
        "            idx += 1\n",
        "        token_idxs.append(word2idx.get(w, word2idx['<UNK>']))\n",
        "    # Rellenar con PAD si es más corto que title_max\n",
        "    if len(token_idxs) < max_size_title:\n",
        "        token_idxs += [word2idx['<PAD>']] * (max_size_title - len(token_idxs))\n",
        "    news2idx[news_id] = token_idxs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upo5CjpX1bW-",
        "outputId": "129ce396-bca8-465d-a6a2-87cfa91c7e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51282/51282 [00:02<00:00, 18283.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word2idx)\n",
        "print(f'Vocabulario: {vocab_size} palabras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUGgNd7o1can",
        "outputId": "3b7c1b98-88ea-4d89-869e-ecad350de768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario: 37272 palabras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for _, row in tqdm(behavior_train.iterrows(), total=behavior_train.shape[0]):\n",
        "    hist_str = row['History']\n",
        "    hist_ids = [] if pd.isna(hist_str) else [nid for nid in hist_str.split() if nid]\n",
        "    impr = row['ImpressionID']\n",
        "    imps = [] if pd.isna(row['Impressions']) else row['Impressions'].split()\n",
        "    for imp in imps:\n",
        "        if len(imp) == 0:\n",
        "            continue\n",
        "        parts = imp.split('-')\n",
        "        if len(parts) != 2:\n",
        "            continue\n",
        "        news_id, click = parts[0], parts[1]\n",
        "        label = int(click)\n",
        "        data.append((impr, hist_ids, news_id, label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFUNeOhO1djW",
        "outputId": "09d7716e-af3e-4549-a2e8-c4905c4d074f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 126695/126695 [00:15<00:00, 8107.56it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total de ejemplos de interacción: {len(data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAJKAq511e2m",
        "outputId": "69ba8dc1-b18c-494a-b11d-c62cebaa63e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de ejemplos de interacción: 4621015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = []\n",
        "\n",
        "for _, row in tqdm(behavior_val.iterrows(), total=behavior_val.shape[0]):\n",
        "    hist_str = row['History']\n",
        "    hist_ids = [] if pd.isna(hist_str) else [nid for nid in hist_str.split() if nid]\n",
        "    impr = row['ImpressionID']\n",
        "    imps = row['Impressions'].split()\n",
        "    for imp in imps:\n",
        "        if len(imp) == 0:\n",
        "            continue\n",
        "        parts = imp.split('-')\n",
        "        if len(parts) != 2:\n",
        "            continue\n",
        "        news_id, click = parts[0], parts[1]\n",
        "        val_data.append((impr, hist_ids, news_id, int(click)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p30Gw8JU1f7O",
        "outputId": "cac6d1f3-951e-4991-b05c-64fc10cbe961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30270/30270 [00:03<00:00, 8235.70it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total ejemplos validación: {len(val_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4dB2RD61hH2",
        "outputId": "29695a93-511d-4d90-92e8-80ade46e2141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total ejemplos validación: 1222429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MINDListDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Devuelve:\n",
        "        hist_tensor  : [hist_max, title_max]\n",
        "        cand_tensor  : [C,         title_max]\n",
        "        label_tensor : [C]  (0/1, un solo 1)\n",
        "        impr_id      : str\n",
        "    \"\"\"\n",
        "    def __init__(self, interactions, news2idx, word2idx,\n",
        "                 hist_max, title_max):\n",
        "        self.news2idx  = news2idx\n",
        "        self.word2idx  = word2idx\n",
        "        self.hist_max  = hist_max\n",
        "        self.title_max = title_max\n",
        "\n",
        "        # Agrupar ejemplos por impresión -----------------------------\n",
        "        sessions = defaultdict(list)\n",
        "        for impr, hist_ids, cand_id, label in interactions:\n",
        "            sessions[impr].append((hist_ids, cand_id, label))\n",
        "        self.impr_ids = list(sessions.keys())\n",
        "        self.sessions = sessions\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.impr_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        impr   = self.impr_ids[idx]\n",
        "        triples = self.sessions[impr]           # lista de (hist, cand, label)\n",
        "\n",
        "        # -------- historial (todos los candidatos comparten el mismo) -----\n",
        "        hist_ids = triples[0][0][-self.hist_max:]        # recorte por la derecha\n",
        "        hist_seq = [self.news2idx.get(nid,\n",
        "                    [self.word2idx['<PAD>']]*self.title_max) for nid in hist_ids]\n",
        "        while len(hist_seq) < self.hist_max:\n",
        "            hist_seq.insert(0, [self.word2idx['<PAD>']]*self.title_max)\n",
        "\n",
        "        # -------- candidatos + etiquetas -------------------------------\n",
        "        cand_seqs, labels = [], []\n",
        "        for _, cand_id, lbl in triples:\n",
        "            cand_seqs.append(\n",
        "                self.news2idx.get(cand_id,\n",
        "                     [self.word2idx['<PAD>']]*self.title_max))\n",
        "            labels.append(lbl)\n",
        "\n",
        "        return (torch.tensor(hist_seq,  dtype=torch.long),        # [H,L]\n",
        "                torch.tensor(cand_seqs, dtype=torch.long),        # [C,L]\n",
        "                torch.tensor(labels,   dtype=torch.float),        # [C]\n",
        "                impr)"
      ],
      "metadata": {
        "id": "ir04iVO71jUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn_list(batch):\n",
        "    \"\"\"\n",
        "    Devuelve:\n",
        "        hist_batch  : [B, H, L]\n",
        "        cand_batch  : [B, C_max, L]\n",
        "        label_batch : [B, C_max]  (0/1, padded con -1)\n",
        "        mask_batch  : [B, C_max]  (True donde existe candidato)\n",
        "        impr_batch  : list[str]\n",
        "    \"\"\"\n",
        "    hist_list, cand_list, label_list, impr_list = zip(*batch)\n",
        "\n",
        "    # Historial: tamaño fijo\n",
        "    hist_batch = torch.stack(hist_list)             # [B,H,L]\n",
        "\n",
        "    # Candidatos: pad al máximo C del batch\n",
        "    C_max = max(x.size(0) for x in cand_list)\n",
        "    L     = cand_list[0].size(1)\n",
        "    pad_val = 0  # token PAD\n",
        "\n",
        "    cand_pad   = torch.full((len(batch), C_max, L), pad_val, dtype=torch.long)\n",
        "    label_pad  = torch.full((len(batch), C_max),    -1,      dtype=torch.float)\n",
        "    mask_pad   = torch.zeros(len(batch), C_max,     dtype=torch.bool)\n",
        "\n",
        "    for i,(cands, labels) in enumerate(zip(cand_list, label_list)):\n",
        "        C = cands.size(0)\n",
        "        cand_pad[i,:C]  = cands\n",
        "        label_pad[i,:C] = labels\n",
        "        mask_pad[i,:C]  = 1\n",
        "\n",
        "    return (hist_batch.to(device),\n",
        "            cand_pad.to(device),\n",
        "            label_pad.to(device),\n",
        "            mask_pad.to(device),\n",
        "            list(impr_list))\n"
      ],
      "metadata": {
        "id": "euYhosJa1kr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_hist_title = 50\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "4wqU253z1lsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MINDListDataset(data, news2idx, word2idx, max_hist_title, max_size_title)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_list)\n",
        "\n",
        "val_dataset = MINDListDataset(val_data, news2idx, word2idx, max_hist_title, max_size_title)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_list)"
      ],
      "metadata": {
        "id": "zlFMx44z1mwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 300\n",
        "num_heads = 20\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "Lh5_7mMH1nyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove = True\n",
        "\n",
        "if glove:\n",
        "    embedding_matrix = np.random.normal(scale=0.6, size=(vocab_size, embed_dim))\n",
        "    found = 0\n",
        "    with open(\"glove.6B.300d.txt\", 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.rstrip().split(' ')\n",
        "            word = parts[0]\n",
        "            if word in word2idx:\n",
        "                vec = np.array(parts[1:], dtype=np.float32)\n",
        "                if vec.shape[0] == embed_dim:\n",
        "                    embedding_matrix[word2idx[word]] = vec\n",
        "                    found += 1\n",
        "    print(f'Palabras encontradas en GloVe: {found}/{vocab_size}')\n",
        "    embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float)\n",
        "else:\n",
        "    embedding_matrix = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5iMvqeX1o03",
        "outputId": "5465d1f2-5293-45de-e0f4-988778bbeb66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras encontradas en GloVe: 28233/37272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FastformerAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Atención Fastformer (Atención aditiva global) que reemplaza nn.MultiheadAttention.\n",
        "    Opera con entradas de forma (L, B, E) o (B, L, E), realizando la proyección Q, K, V\n",
        "    por separado, obteniendo vectores globales y propagando interacciones por producto\n",
        "    elemento a elemento, según Fastformer (Fastformer: Additive Attention Can Be All You Need).\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, num_heads, dropout=0.0):\n",
        "        super(FastformerAttention, self).__init__()\n",
        "        assert embed_dim % num_heads == 0, \"embed_dim debe ser divisible por num_heads\"\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        # Proyecciones lineales para Q, K, V (similar a multi-cabeza estándar)\n",
        "        self.W_q = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "        self.W_k = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "        self.W_v = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "        # Parámetros de atención aditiva por cabeza (vectores de peso para Q y K)\n",
        "        # Formato (num_heads, head_dim) para aplicar dot-product con cada vector de dimensión head_dim\n",
        "        self.attn_wq = nn.Parameter(torch.Tensor(num_heads, self.head_dim))\n",
        "        self.attn_wk = nn.Parameter(torch.Tensor(num_heads, self.head_dim))\n",
        "        # Capa de salida tras concatenar cabezas\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # Inicialización\n",
        "        nn.init.xavier_uniform_(self.W_q.weight)\n",
        "        nn.init.xavier_uniform_(self.W_k.weight)\n",
        "        nn.init.xavier_uniform_(self.W_v.weight)\n",
        "        nn.init.xavier_uniform_(self.out_proj.weight)\n",
        "        nn.init.zeros_(self.W_q.bias)\n",
        "        nn.init.zeros_(self.W_k.bias)\n",
        "        nn.init.zeros_(self.W_v.bias)\n",
        "        nn.init.zeros_(self.out_proj.bias)\n",
        "        nn.init.xavier_uniform_(self.attn_wq)\n",
        "        nn.init.xavier_uniform_(self.attn_wk)\n",
        "\n",
        "    def forward(self, query, key, value):\n",
        "        \"\"\"\n",
        "        query, key, value: tensores de forma (L, B, E) ó (S, N, E) donde\n",
        "        L=longitud de secuencia, B=batch, E=embed_dim.\n",
        "        Fastformer es simétrico en q=k=v, pero aceptamos tres argumentos para compatibilidad.\n",
        "        \"\"\"\n",
        "        # Permutar para batch-first: [B, L, E]\n",
        "        transpose = False\n",
        "        if query.dim() == 3 and query.shape[0] != query.shape[1]:\n",
        "            # Asumimos forma (L, B, E)\n",
        "            query = query.transpose(0, 1)\n",
        "            key = key.transpose(0, 1)\n",
        "            value = value.transpose(0, 1)\n",
        "            transpose = True\n",
        "        # Proyectar Q, K, V\n",
        "        # Ahora shapes: [B, L, E]\n",
        "        Q = self.W_q(query)   # [B, L, E]\n",
        "        K = self.W_k(key)     # [B, L, E]\n",
        "        V = self.W_v(value)   # [B, L, E]\n",
        "        B, L, E = Q.size()\n",
        "        H = self.num_heads\n",
        "        D = self.head_dim\n",
        "        # Dividir en cabezas: [B, L, H, D]\n",
        "        Q = Q.view(B, L, H, D)\n",
        "        K = K.view(B, L, H, D)\n",
        "        V = V.view(B, L, H, D)\n",
        "        # Reordenar para [B, H, L, D]\n",
        "        Q = Q.permute(0, 2, 1, 3)\n",
        "        K = K.permute(0, 2, 1, 3)\n",
        "        V = V.permute(0, 2, 1, 3)\n",
        "        # =========== Fastformer Steps ===========\n",
        "        # 1) Atención aditiva sobre Q para obtener q_global [B, H, D]\n",
        "        # Calculamos puntuaciones: sum_{j}( w_q[h,j] * Q[...,j] )\n",
        "        # w_q: [H, D], Q: [B, H, L, D]\n",
        "        # Producto elemento a elemento y sumar sobre dimensión D:\n",
        "        # scores_q: [B, H, L]\n",
        "        scores_q = (Q * self.attn_wq.unsqueeze(0).unsqueeze(2)).sum(dim=-1)  # [B, H, L]\n",
        "        alpha = torch.softmax(scores_q, dim=-1)  # [B, H, L]\n",
        "        # Obtener vector q_global: suma ponderada de Q sobre L\n",
        "        # alpha: [B, H, L], Q: [B, H, L, D] -> q_global: [B, H, D]\n",
        "        q_global = torch.einsum('bhl,bhld->bhd', alpha, Q)\n",
        "        # 2) Interactuar q_global con cada K por producto elemento a elemento -> K'\n",
        "        # Extendemos q_global para cada posición L: [B, H, 1, D] * [B, H, L, D] -> [B, H, L, D]\n",
        "        K_prime = q_global.unsqueeze(2) * K  # [B, H, L, D]\n",
        "        # 3) Atención aditiva sobre K_prime para obtener k_global [B, H, D]\n",
        "        scores_k = (K_prime * self.attn_wk.unsqueeze(0).unsqueeze(2)).sum(dim=-1)  # [B, H, L]\n",
        "        beta = torch.softmax(scores_k, dim=-1)  # [B, H, L]\n",
        "        k_global = torch.einsum('bhl,bhld->bhd', beta, K_prime)  # [B, H, D]\n",
        "        # 4) Interactuar k_global con cada V -> V'\n",
        "        V_prime = k_global.unsqueeze(2) * V  # [B, H, L, D]\n",
        "        # Rearmar V' combinando cabezas: [B, H, L, D] -> [B, L, H*D]\n",
        "        V_prime = V_prime.permute(0, 2, 1, 3).contiguous().view(B, L, H * D)  # [B, L, E]\n",
        "        # Capa lineal de salida y agregar Q (residuo)\n",
        "        out = self.out_proj(V_prime)  # [B, L, E]\n",
        "        # Capa residual: sumamos la proyección original de Q antes de dividir cabezas\n",
        "        # Primero reconstruir Q original (bidimensional por cada posición)\n",
        "        Q_orig = Q.permute(0, 2, 1, 3).contiguous().view(B, L, H * D)  # [B, L, E]\n",
        "        out = out + Q_orig\n",
        "        # Opcional: aplicar dropout\n",
        "        out = self.dropout(out)\n",
        "        # Devolver en forma (L, B, E)\n",
        "        if transpose:\n",
        "            out = out.transpose(0, 1).contiguous()\n",
        "        return out"
      ],
      "metadata": {
        "id": "gkNJSt3e1pUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Codificador de noticias: procesa títulos de noticias (secuencias de tokens)\n",
        "    y produce vectores de noticia. Reemplaza la atención multi-cabeza por FastformerAttention.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, title_max, pretrained_emb=None):\n",
        "        super(NewsEncoder, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.title_max = title_max\n",
        "        # Capa de embedding de palabras\n",
        "        self.word_embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "\n",
        "        if pretrained_emb is not None:\n",
        "            self.word_embedding.weight.data.copy_(pretrained_emb)\n",
        "            self.word_embedding.weight.requires_grad = True  # o False si no quieres fine-tune\n",
        "\n",
        "        # Capa convolucional 1D para extraer características locales de palabras (opcional, similar a arquitectura original)\n",
        "        # Usamos múltiples filtros 1xD para captar n-gramas de tamaño 3 por ejemplo\n",
        "        self.conv = nn.Conv1d(in_channels=embed_dim, out_channels=embed_dim, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        # Atención Fastformer sobre la secuencia de características de palabras\n",
        "        self.self_attn = FastformerAttention(embed_dim, num_heads, dropout=0.1)\n",
        "        # Atención aditiva para agregar las palabras importantes en el título\n",
        "        self.attn_vector = nn.Linear(embed_dim, 1)  # para puntuación de cada palabra\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: tensor de tokens de noticias con forma [B, title_max].\n",
        "        Devuelve: vectores de noticias de forma [B, embed_dim].\n",
        "        \"\"\"\n",
        "        # Embedding y extracción de características locales\n",
        "        # Palabras: [B, title_max, E] -> conv espera [B, E, title_max]\n",
        "        emb = self.word_embedding(x)            # [B, L, E]\n",
        "        emb = emb.transpose(1, 2)               # [B, E, L]\n",
        "        conv_out = self.relu(self.conv(emb))    # [B, E, L]\n",
        "        conv_out = conv_out.transpose(1, 2)     # [B, L, E]\n",
        "        # Atención Fastformer (auto-atención) entre las posiciones de palabras\n",
        "        # FastformerAttention espera (L, B, E) o (B, L, E); adaptamos:\n",
        "        conv_out_trans = conv_out.transpose(0, 1).contiguous()  # [L, B, E]\n",
        "        attn_out = self.self_attn(conv_out_trans, conv_out_trans, conv_out_trans)  # [L, B, E]\n",
        "        attn_out = attn_out.transpose(0, 1)  # [B, L, E]\n",
        "        # Atención aditiva para obtener vector final de noticia\n",
        "        # Calcular puntuación de importancia para cada palabra\n",
        "        scores = self.attn_vector(attn_out).squeeze(-1)  # [B, L]\n",
        "        weights = self.softmax(scores)                    # [B, L]\n",
        "        news_vector = torch.bmm(weights.unsqueeze(1), attn_out).squeeze(1)  # [B, E]\n",
        "        return news_vector  # [B, embed_dim]\n",
        "\n",
        "class UserEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Codificador de usuario: agrega vectores de noticias historiales usando Fastformer.\n",
        "    Toma un historial de noticias y devuelve un vector de usuario.\n",
        "    \"\"\"\n",
        "    def __init__(self, news_encoder, embed_dim, num_heads, hist_max):\n",
        "        super(UserEncoder, self).__init__()\n",
        "        self.news_encoder = news_encoder  # instancia de NewsEncoder para codificar cada noticia\n",
        "        self.hist_max = hist_max\n",
        "        # Atención Fastformer sobre la secuencia de vectores de noticia del historial\n",
        "        self.self_attn = FastformerAttention(embed_dim, num_heads, dropout=0.1)\n",
        "        # Atención aditiva para agregar las noticias más relevantes del historial\n",
        "        self.attn_vector = nn.Linear(embed_dim, 1)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, hist_x):\n",
        "        \"\"\"\n",
        "        hist_x: tensor de tokens de noticias de historial con forma [B, hist_max, title_max].\n",
        "        Devuelve: vector de usuario de forma [B, embed_dim].\n",
        "        \"\"\"\n",
        "        B, H, L = hist_x.size()\n",
        "        # Codificar cada noticia en el historial\n",
        "        hist_x_flat = hist_x.view(B * H, L)                  # [B*H, title_max]\n",
        "        news_vectors = self.news_encoder(hist_x_flat)        # [B*H, embed_dim]\n",
        "        news_vectors = news_vectors.view(B, H, -1)           # [B, hist_max, embed_dim]\n",
        "        # Atención Fastformer sobre las noticias del historial\n",
        "        nv_trans = news_vectors.transpose(0, 1).contiguous() # [H, B, E]\n",
        "        attn_out = self.self_attn(nv_trans, nv_trans, nv_trans)  # [H, B, E]\n",
        "        attn_out = attn_out.transpose(0, 1)                  # [B, H, E]\n",
        "        # Atención aditiva para agregar vectores de noticias importantes\n",
        "        scores = self.attn_vector(attn_out).squeeze(-1)      # [B, H]\n",
        "        weights = self.softmax(scores)                       # [B, H]\n",
        "        user_vector = torch.bmm(weights.unsqueeze(1), attn_out).squeeze(1)  # [B, E]\n",
        "        return user_vector  # [B, embed_dim]"
      ],
      "metadata": {
        "id": "JPmn3pVg11NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FastformerNRMS(nn.Module):\n",
        "    \"\"\"\n",
        "    Modelo NRMS modificado con Fastformer.\n",
        "    Mantiene la misma interfaz: forward(hist_tensor, cand_tensor).\n",
        "    hist_tensor: [B, hist_max, title_max], cand_tensor: [B, cand_count, title_max].\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, title_max, hist_max, pretrained_emb=None):\n",
        "        super(FastformerNRMS, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.title_max = title_max\n",
        "        self.hist_max = hist_max\n",
        "        # News encoder y user encoder con Fastformer\n",
        "        self.news_encoder = NewsEncoder(vocab_size, embed_dim, num_heads, title_max, pretrained_emb)\n",
        "        self.user_encoder = UserEncoder(self.news_encoder, embed_dim, num_heads, hist_max)\n",
        "        # (Opcional) proyección final o dropout\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, hist_tensor, cand_tensor, mask=None):\n",
        "        \"\"\"\n",
        "        hist_tensor : [B, hist_max, title_max]\n",
        "        cand_tensor : [B, C,       title_max]\n",
        "        mask        : [B, C]  (bool) – True donde el candidato existe\n",
        "        \"\"\"\n",
        "        B, H, L = hist_tensor.size()\n",
        "        _, C, _ = cand_tensor.size()\n",
        "        # Codificar usuario\n",
        "        user_vector = self.user_encoder(hist_tensor)            # [B, E]\n",
        "        # Codificar candidatos (aplicar NewsEncoder a cada candidato)\n",
        "        cand_flat = cand_tensor.view(B * C, L)                  # [B*C, title_max]\n",
        "        cand_vecs = self.news_encoder(cand_flat)               # [B*C, E]\n",
        "        cand_vecs = cand_vecs.view(B, C, -1)                   # [B, cand_count, E]\n",
        "        # Calcular similaridad (producto punto usuario con cada candidato)\n",
        "        # Expandir user_vector para combinar con candidatos\n",
        "\n",
        "        cand_vecs = self.dropout(cand_vecs)\n",
        "        user_vector = self.dropout(user_vector)\n",
        "\n",
        "        user_exp = user_vector.unsqueeze(1)                    # [B, 1, E]\n",
        "        logits = torch.sum(cand_vecs * user_exp, dim=-1)       # [B, cand_count]\n",
        "\n",
        "        if mask is not None:\n",
        "            logits = logits.masked_fill(~mask, -1e9)             # -∞ donde no hay candidato\n",
        "\n",
        "        return logits                                            # [B,C]"
      ],
      "metadata": {
        "id": "TyZkcEl512j7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastformerNRMS(vocab_size, embed_dim, num_heads, max_size_title, max_hist_title,\n",
        "             pretrained_emb=embedding_matrix.to(device) if embedding_matrix is not None else None)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ytcEQxLA14d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def ndcg_score(labels, scores, k=5):\n",
        "    order = np.argsort(scores)[::-1]\n",
        "    labels = np.array(labels)\n",
        "    dcg = 0.0\n",
        "    for i in range(min(k, len(labels))):\n",
        "        rel = labels[order[i]]\n",
        "        dcg += (2**rel - 1) / np.log2(i+2)\n",
        "    ideal = np.sort(labels)[::-1]\n",
        "    idcg = 0.0\n",
        "    for i in range(min(k, int(np.sum(labels)))):\n",
        "        idcg += 1.0 / np.log2(i+2)\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "def mrr_score(labels, scores):\n",
        "    order = np.argsort(scores)[::-1]\n",
        "    labels = np.array(labels)[order]\n",
        "    for rank, label in enumerate(labels, start=1):\n",
        "        if label == 1:\n",
        "            return 1.0 / rank\n",
        "    return 0.0"
      ],
      "metadata": {
        "id": "_tmaqomD2tuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3"
      ],
      "metadata": {
        "id": "q64WVk6a2xjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_ndcg5 = 0.0\n",
        "best_model_state = None\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for hist_batch, cand_batch, label_batch, mask_batch, _ in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(hist_batch, cand_batch, mask_batch)\n",
        "        target = label_batch.argmax(dim=1)        # [B]\n",
        "        loss = criterion(logits, target)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch} - Pérdida promedio: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluación en validación\n",
        "    if val_loader is None:\n",
        "        continue\n",
        "\n",
        "    model.eval()\n",
        "    ndcg5_list, ndcg10_list, mrr_list, auc_list = [], [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for hist_batch, cand_batch, label_batch, mask_batch, impr_batch in val_loader:\n",
        "            logits  = model(hist_batch, cand_batch, mask_batch)  # [B,C]\n",
        "            scores  = logits.cpu().numpy()\n",
        "            labels  = label_batch.cpu().numpy()\n",
        "            masks   = mask_batch.cpu().numpy()\n",
        "\n",
        "            for s, l, m in zip(scores, labels, masks):\n",
        "                # recortar a candidatos reales\n",
        "                s = s[m]        # (C_real,)\n",
        "                l = l[m]        # (C_real,)\n",
        "\n",
        "                ndcg5_list .append(ndcg_score(l, s, k=5))\n",
        "                ndcg10_list.append(ndcg_score(l, s, k=10))\n",
        "                mrr_list  .append(mrr_score(l, s))\n",
        "                if l.max() > 0 and l.min() == 0:     # al menos 1 pos y 1 neg\n",
        "                    auc_list.append(roc_auc_score(l, s))\n",
        "\n",
        "    ndcg5  = np.mean(ndcg5_list)\n",
        "    ndcg10 = np.mean(ndcg10_list)\n",
        "    mrr    = np.mean(mrr_list)\n",
        "    auc    = np.mean(auc_list) if auc_list else 0.0\n",
        "\n",
        "    if ndcg5 > best_ndcg5:\n",
        "        best_ndcg5 = ndcg5\n",
        "        best_model_state = model.state_dict()\n",
        "        print(f\"» Nuevo mejor modelo guardado (nDCG@5 = {ndcg5:.4f})\")\n",
        "\n",
        "    print(f\"Validación – AUC: {auc:.4f} | MRR: {mrr:.4f} | \"\n",
        "          f\"nDCG@5: {ndcg5:.4f} | nDCG@10: {ndcg10:.4f}\")\n",
        "\n",
        "if best_model_state is not None:\n",
        "    torch.save(best_model_state, \"nrms_fastformer_best.pt\")\n",
        "    print(\"Modelo con mejor nDCG@5 guardado en nrms_fastformer_best.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duLvr7fm2yjP",
        "outputId": "23a230af-f059-4102-b2bb-dfc79ca83309"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 3960/3960 [17:11<00:00,  3.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Pérdida promedio: 2.7985\n",
            "» Nuevo mejor modelo guardado (nDCG@5 = 0.3055)\n",
            "Validación – AUC: 0.6429 | MRR: 0.3330 | nDCG@5: 0.3055 | nDCG@10: 0.3661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 3960/3960 [17:06<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Pérdida promedio: 2.8410\n",
            "» Nuevo mejor modelo guardado (nDCG@5 = 0.3103)\n",
            "Validación – AUC: 0.6498 | MRR: 0.3363 | nDCG@5: 0.3103 | nDCG@10: 0.3712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 3960/3960 [17:04<00:00,  3.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Pérdida promedio: 3.4581\n",
            "Validación – AUC: 0.6473 | MRR: 0.3309 | nDCG@5: 0.3054 | nDCG@10: 0.3683\n",
            "Modelo con mejor nDCG@5 guardado en nrms_fastformer_best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def construir_seq2title(news2idx, idx2word, pad_idx=PAD):\n",
        "    seq2title = {}\n",
        "    for token_ids in news2idx.values():\n",
        "        seq_key = tuple(token_ids)                         # <-- clave exactamente igual a lo que entrega el DataLoader\n",
        "        words = [idx2word[i] for i in token_ids if i != pad_idx]\n",
        "        seq2title[seq_key] = \" \".join(words)\n",
        "    return seq2title"
      ],
      "metadata": {
        "id": "YY60zcfeB6Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mostrar_perfil_y_recomendaciones(model, dataloader, seq2title, device, n=3, hist_k=5, stop_on_click=True):\n",
        "    model.eval()\n",
        "    ejemplos_mostrados = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for hist_batch, cand_batch, label_batch, mask_batch, _ in dataloader:\n",
        "            # Mover a device\n",
        "            hist_batch = hist_batch.to(device)\n",
        "            cand_batch = cand_batch.to(device)\n",
        "            label_batch = label_batch.to(device)\n",
        "            mask_batch = mask_batch.to(device)\n",
        "\n",
        "            logits = model(hist_batch, cand_batch, mask_batch)\n",
        "            probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "            labels = label_batch.cpu().numpy()\n",
        "            masks = mask_batch.cpu().numpy()\n",
        "\n",
        "            indices = list(range(len(hist_batch)))\n",
        "            random.shuffle(indices)  # Mezcla los usuarios dentro del batch\n",
        "\n",
        "            for i in indices:\n",
        "                print(f\"\\n--- Usuario {ejemplos_mostrados+1} ---\")\n",
        "\n",
        "                # Historial (máx hist_k)\n",
        "                print(f\"Historial (hasta {hist_k} ítems):\")\n",
        "                contador = 0\n",
        "                for seq in hist_batch[i].cpu().numpy():\n",
        "                    titulo = seq2title.get(tuple(seq), None)\n",
        "                    if titulo:\n",
        "                        print(f\" - {titulo}\")\n",
        "                        contador += 1\n",
        "                        if contador >= hist_k:\n",
        "                            break\n",
        "\n",
        "                # Candidatos\n",
        "                print(\"\\nCandidatos (ordenados por score):\")\n",
        "                scores = probs[i]\n",
        "                cand_seqs = cand_batch[i].cpu().numpy()\n",
        "                mask_line = masks[i].astype(bool)\n",
        "                valid_idx = scores[mask_line].argsort()[::-1]\n",
        "                real_pos = np.where(mask_line)[0][valid_idx]\n",
        "\n",
        "                for j in real_pos:\n",
        "                    seq = tuple(cand_seqs[j])\n",
        "                    titulo = seq2title.get(seq, \"[Título desconocido]\")\n",
        "                    marcador = \"✔\" if labels[i][j] == 1 else \"✖\"\n",
        "                    print(f\"  ({marcador}) {titulo}\")\n",
        "                    if stop_on_click and labels[i][j] == 1:\n",
        "                        break\n",
        "\n",
        "                ejemplos_mostrados += 1\n",
        "                if ejemplos_mostrados >= n:\n",
        "                    return"
      ],
      "metadata": {
        "id": "OgLLWrv-Zu5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PAD = word2idx['<PAD>']\n",
        "idx2word = {v: k for k, v in word2idx.items()}\n",
        "seq2title = construir_seq2title(news2idx, idx2word)"
      ],
      "metadata": {
        "id": "CuC-zQSeDp9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplos de recomendaciones a usuarios\n",
        "\n",
        "\"n\" indica la cantidad de usuarios de ejemplo\n",
        "\"hist_k\" la cantidad de noticias del historial que se mostrará\n",
        "\"stop_on_click\" si se quieren mostrar todos los candidatos o solo hasta que el usuario hizo click. Las noticias candidatas están ordenadas por score"
      ],
      "metadata": {
        "id": "XP7x_h43NF31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\nMostrando ejemplos de perfiles y recomendaciones del modelo:\")\n",
        "mostrar_perfil_y_recomendaciones(model, val_loader, seq2title, device, n=3, hist_k=3, stop_on_click=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAwe64RvEYAZ",
        "outputId": "a395637f-dd65-4683-c8c7-63b958c13a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mostrando ejemplos de perfiles y recomendaciones del modelo:\n",
            "\n",
            "--- Usuario 1 ---\n",
            "Historial (hasta 3 ítems):\n",
            " - 50 movies you definitely watched in the '90s and forgot about\n",
            " - china is leasing an entire pacific island its residents are shocked\n",
            " - kawhi back in canada nba gms think he'll go back to finals\n",
            "\n",
            "Candidatos (ordenados por score):\n",
            "  (✖) why aren't wages rising faster even with low unemployment trade war weaker economy are among reasons\n",
            "  (✖) 'one in a million' deer captured on camera in michigan woods\n",
            "  (✔) hernandez anthony davis' impact on lebron james apparent even when he doesn't play\n",
            "\n",
            "--- Usuario 2 ---\n",
            "Historial (hasta 3 ítems):\n",
            " - america's largest auto retailer sells customers defective used cars report says\n",
            " - china wants more talks before signing trade deal with trump\n",
            " - china wants more talks before signing trade deal with trump\n",
            "\n",
            "Candidatos (ordenados por score):\n",
            "  (✔) judge calls usc dad a 'thief ' gives longest prison sentence so far in college admissions scandal\n",
            "\n",
            "--- Usuario 3 ---\n",
            "Historial (hasta 3 ítems):\n",
            " - national dessert day where to get free dessert at wendy's tgi friday and more\n",
            " - 'go back to work' outcry over deaths on amazon's warehouse floor\n",
            " - 25 stars you didn't know got their start in commercials\n",
            "\n",
            "Candidatos (ordenados por score):\n",
            "  (✖) 'one in a million' deer captured on camera in michigan woods\n",
            "  (✖) survivor contestant accused of 'inappropriate touching ' 2 players admit to using allegations to win\n",
            "  (✔) 50 amazing gifts for every type of person and budget\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\nMostrando ejemplos de perfiles y recomendaciones del modelo:\")\n",
        "mostrar_perfil_y_recomendaciones(model, val_loader, seq2title, device, n=5, hist_k=5, stop_on_click=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff8H8v6fMZpz",
        "outputId": "a55a6e38-1cf7-415b-ae4d-24fec96cfcf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mostrando ejemplos de perfiles y recomendaciones del modelo:\n",
            "\n",
            "--- Usuario 1 ---\n",
            "Historial (hasta 5 ítems):\n",
            " - 50 movies you definitely watched in the '90s and forgot about\n",
            " - china is leasing an entire pacific island its residents are shocked\n",
            " - kawhi back in canada nba gms think he'll go back to finals\n",
            " - the news in cartoons\n",
            " - trump declares 'big success' in syria lifts sanctions on turkey\n",
            "\n",
            "Candidatos (ordenados por score):\n",
            "  (✖) why aren't wages rising faster even with low unemployment trade war weaker economy are among reasons\n",
            "  (✖) 'one in a million' deer captured on camera in michigan woods\n",
            "  (✔) hernandez anthony davis' impact on lebron james apparent even when he doesn't play\n",
            "\n",
            "--- Usuario 2 ---\n",
            "Historial (hasta 5 ítems):\n",
            " - we tried fatburger's impossible burger here's our review\n",
            "\n",
            "Candidatos (ordenados por score):\n",
            "  (✖) 65 best fall soups that will warm you and your family up all season long\n",
            "  (✖) car of marine linked to virginia slaying is found in south carolina authorities say\n",
            "  (✖) can you answer these real jeopardy questions about tv shows\n",
            "  (✖) dolly parton is rocking a thigh high slit at the cma awards and she looks incredible\n",
            "  (✖) the bakery behind doubletree's famous chocolate chip cookie bakes more than 100 million cookies a year\n",
            "  (✖) just try not going back for seconds of this over the top cabbage gratin\n",
            "  (✖) here's the best small town in every state\n",
            "  (✖) 9 amazing transgender women who changed history\n",
            "  (✖) scarlett johansson regrets being hyper sexualized early in her career\n",
            "  (✔) penn cancels remainder of women's volleyball season after 'vulgar offensive' posters found in locker room\n",
            "\n",
            "--- Usuario 3 ---\n",
            "Historial (hasta 5 ítems):\n",
            " - who the houston roughnecks took in the xfl draft\n",
            " - cuba gooding jr pleads not guilty to sex misconduct claims\n",
            " - saints dbs mocked bears rb tarik cohen for being short during heated argument\n",
            " - ex model accuses jeffrey epstein's friend of rape\n",
            " - mlb bans women who flashed their chests behind home plate during game 5 of world series\n",
            "\n",
            "Candidatos (ordenados por score):\n",
            "  (✔) wynonna judd's daughter 23 released from prison 6 years early after being granted parole\n",
            "\n",
            "--- Usuario 4 ---\n",
            "Historial (hasta 5 ítems):\n",
            " - panera bread worker fired after tiktok exposed frozen mac and cheese\n",
            " - miguel cervantes' wife reveals daughter 3 'died in my arms' after entering hospice care\n",
            " - he had been homeless for decades then old friends saw his photo in a newspaper\n",
            " - former president jimmy carter suffers pelvic fracture after falling in georgia home\n",
            " - woman fights back after grandparents scam targets her father\n",
            "\n",
            "Candidatos (ordenados por score):\n",
            "  (✖) experts crack mystery of ancient egypt's sacred bird mummies\n",
            "  (✔) car of marine linked to virginia slaying is found in south carolina authorities say\n",
            "\n",
            "--- Usuario 5 ---\n",
            "Historial (hasta 5 ítems):\n",
            " - china is leasing an entire pacific island its residents are shocked\n",
            " - refugees at a camp in iraqi kurdistan express anger over u s betrayal\n",
            " - as u s leaves allies in syria kurdish commander struggles with fallout\n",
            " - u s has begun reducing troops in afghanistan commander says\n",
            " - pedestrian fatalities on u s roads hit almost 30 year high\n",
            "\n",
            "Candidatos (ordenados por score):\n",
            "  (✔) small canadian island irate that americans keep opening their mail\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\nMostrando ejemplos de perfiles y recomendaciones del modelo:\")\n",
        "mostrar_perfil_y_recomendaciones(model, val_loader, seq2title, device, n=5, hist_k=1000, stop_on_click=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvRAzzfJMbBB",
        "outputId": "b82d7bb5-3b7e-4f03-a461-113841b553f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mostrando ejemplos de perfiles y recomendaciones del modelo:\n",
            "\n",
            "--- Usuario 1 ---\n",
            "Historial (hasta 1000 ítems):\n",
            " - dad's post about his wife's 'imperfect' postpartum body is getting all the applause\n",
            " - nfl world reacts to officials handing packers win over lions\n",
            " - off to the world series these nationals have proved everyone wrong\n",
            " - kate middleton just wore a tiara for a very special reason\n",
            " - 'this is corruption plain and simple' democrats and media respond to g 7 being held at trump resort\n",
            " - jennifer lawrence's a list wedding everything we know\n",
            " - michelle obama shows off her abs in new workout photo 'i'm always glad i hit the gym'\n",
            " - justin bieber shares new photo of wife hailey baldwin from wedding weekend 'sexy wifey alert'\n",
            " - jennifer lawrence hired a food truck for her wedding and the owner had no idea who she was\n",
            " - the 25 greatest english rock bands\n",
            " - president donald trump greeted with boos at game 5 of world series fans chant 'lock him up'\n",
            " - trump's visit to chicago creates stir before he even arrives\n",
            " - fact checker trump's shiny new talking point about income growth\n",
            " - democrat asks fec to investigate trump campaign declining to pay police bills\n",
            " - country music's biggest scandals\n",
            " - robert evans 'chinatown' producer and paramount chief dies at 89\n",
            " - trump attorneys assert immunity from broad sweep of law\n",
            " - shouting match erupts in vindman deposition as democrats accuse republicans of trying to out whistleblower\n",
            " - trump expected to attend ufc 244\n",
            " - ap norc poll trump approval steady as impeachment rages\n",
            " - pamela anderson gets backlash after wearing a native american headdress for halloween\n",
            " - 100 most popular country music stars\n",
            " - rare deer spotted in montana\n",
            " - 6 year old can't contain tears of joy after meeting baby sister\n",
            " - catherine deneuve hospitalized after mild stroke\n",
            " - impeachment inquiry tests ties between barr and trump\n",
            " - why everyone in the royal family is wearing a red poppy pin this week\n",
            " - a guide to the 2019 people's choice awards nominees' significant others\n",
            "\n",
            "Candidatos (ordenados por score):\n",
            "  (✔) senate gop waves trump off early motion to dismiss impeachment charges\n",
            "\n",
            "--- Usuario 2 ---\n",
            "Historial (hasta 1000 ítems):\n",
            " - 'wheel of fortune' guest delivers hilarious off the rails introduction\n",
            " - woman suspect dead at 'tarzan' actor ron ely's california residence\n",
            " - neil patrick harris has surgery on his hand after a sea urchin accident while on holiday\n",
            " - u s supreme court divided over kansas immigrant identity theft case\n",
            " - trump says he thought family of uk teen wanted meeting with diplomat's wife\n",
            " - food network star carl ruiz died of clogged arteries\n",
            " - 'time was of the essence' politicians add to reward for missing 3 year old\n",
            " - 'tarzan' actor ron ely actor's son allegedly killed his mother before deputies shot and killed him sheriff's office says\n",
            " - judge blocks trump from easing energy rules in us west\n",
            " - biden expands edge in u s democratic nomination race reuters ipsos poll\n",
            " - civil rights groups slam rnc for 'fraudulent' census mailers to montana residents\n",
            " - rosie o'donnell barbara walters isn't 'up to speaking to people' right now\n",
            " - cincinnati school board candidate accused of 'pretending to be black' in his ads\n",
            " - trump allies craft list of potential mulvaney replacements\n",
            " - 'go back to work' outcry over deaths on amazon's warehouse floor\n",
            " - if you want baseball like it used to be this is the world series for you\n",
            " - four flight attendants were arrested in miami's airport after bringing in thousands in cash police say\n",
            " - body of missing alabama girl found 2 being charged\n",
            " - 'angel' car saves arizona family after smashing into suspected drunk driver running red light video shows\n",
            " - mountain skeleton may be man from japanese internment camp\n",
            " - judge brad pitt others can be sued over new orleans homes\n",
            " - solomons vetoes chinese 'lease' on pacific island\n",
            " - the week in history oct 28 nov 3\n",
            " - rep katie hill's lawyers send cease and desist letter to dailymail com over nude photos\n",
            " - devos held in contempt for violating judge's order on student loans\n",
            " - ian poulter posts incredible video of flooded japan golf course hosting pga tour\n",
            " - 'slender man' survivor's brother 'i couldn't believe that kind of thing' happened\n",
            " - trump records 'strongly corroborate' sex assault claims accuser says\n",
            " - mitch mcconnell snubbed by elijah cummings' pallbearer in handshake line at u s capitol ceremony\n",
            " - zimbabwe sent 30 baby elephants to china says rights group\n",
            " - cummings' widow responds to trump's attacks gets standing ovation\n",
            " - homeowner says a mystery object damaged his house it didn't fall from a plane faa says\n",
            " - trump's syria troop withdrawal complicated plans for al baghdadi raid\n",
            " - family of slain isis hostage says they secretly met with her captors in iraq\n",
            " - nunes aide is leaking the ukraine whistleblower's name sources say\n",
            " - trump says likely baghdadi successor killed by u s troops\n",
            " - photos show the white house decked out in spooky trees and pumpkins as the trumps celebrated halloween a few days\n",
            " - kevin spacey won't be charged in sexual assault case after accuser dies\n",
            " - pink on why she didn't headline the 2019 super bowl halftime show after offer\n",
            " - the 'whimpering' terrorist only trump seems to have heard\n",
            " - 30 thanksgiving casserole recipes\n",
            " - she fought for muslim women then she was found dead\n",
            " - convicted ex nfl tight end kellen winslow ii has cte symptoms his attorneys say\n",
            " - before his execution a death row inmate told his victim's family he forgives them\n",
            " - man goes to adoption event and finds his long lost dog\n",
            " - young and the restless star william wintersole dies at 88\n",
            " - meghan mccain confronts trump jr 'you and your family have hurt a lot of people'\n",
            " - far reaching snowstorm may take shape over us\n",
            " - trump seethes after ny judge orders him to pay 2 million for misusing charitable funds 'no wonder why we are\n",
            " - republicans urge bevin to provide proof of election fraud or concede\n",
            "\n",
            "Candidatos (ordenados por score):\n",
            "  (✖) mo'nique files race and sex discrimination suit against netflix\n",
            "  (✖) aaron carter admitted to florida hospital\n",
            "  (✖) nor'easter to grind at us east coast this weekend\n",
            "  (✖) powerful side by side portraits show people over 100 years old next to their younger selves\n",
            "  (✖) choosing the right winter tires for snow and ice a quick guide\n",
            "  (✖) family told to take down christmas display because it's too soon to decorate\n",
            "  (✖) the latest on brad pitt and angelina jolie's post split relationship plus more news\n",
            "  (✖) sears is laying off hundreds of corporate employees after announcing 96 store closings\n",
            "  (✖) student's drone footage shows whale swimming around california surfers\n",
            "  (✔) trump admin preparing to take over private land for border wall\n",
            "\n",
            "--- Usuario 3 ---\n",
            "Historial (hasta 1000 ítems):\n",
            " - we tried fatburger's impossible burger here's our review\n",
            "\n",
            "Candidatos (ordenados por score):\n",
            "  (✖) 65 best fall soups that will warm you and your family up all season long\n",
            "  (✖) car of marine linked to virginia slaying is found in south carolina authorities say\n",
            "  (✖) can you answer these real jeopardy questions about tv shows\n",
            "  (✖) dolly parton is rocking a thigh high slit at the cma awards and she looks incredible\n",
            "  (✖) the bakery behind doubletree's famous chocolate chip cookie bakes more than 100 million cookies a year\n",
            "  (✖) just try not going back for seconds of this over the top cabbage gratin\n",
            "  (✖) here's the best small town in every state\n",
            "  (✖) 9 amazing transgender women who changed history\n",
            "  (✖) scarlett johansson regrets being hyper sexualized early in her career\n",
            "  (✔) penn cancels remainder of women's volleyball season after 'vulgar offensive' posters found in locker room\n",
            "\n",
            "--- Usuario 4 ---\n",
            "Historial (hasta 1000 ítems):\n",
            " - marine corps vet who served in iraq deported to el salvador\n",
            " - robert evans 'chinatown' producer and paramount chief dies at 89\n",
            " - america is sitting on an excess of 40 million pounds of uneaten bacon a 48 year high\n",
            " - joe biden reportedly denied communion at a south carolina church because of his stance on abortion\n",
            " - multiple houses on fire after plane crashes in nj\n",
            " - famed peter luger steakhouse responds to 0 star new york times review\n",
            " - lindsay lohan's dad weighs in on her relationship with the saudi crown prince\n",
            " - fire in the hole salmon cannon helps salmon safely migrate to other side of dams\n",
            " - katy perry sued for 150k by photo agency for 3 year old pic\n",
            " - celebrity halloween costume fails\n",
            " - the toxic bubble of technical debt threatening america\n",
            " - bartender tipped with winning 50k lottery ticket\n",
            " - kevin spacey won't be charged in sexual assault case after accuser dies\n",
            " - pennsylvania mom allegedly handed 1 month old baby to bus driver walked away report\n",
            " - act of kindness days before christmas ended with woman beaten to death suspects finally sentenced\n",
            " - rescue cat returns the favor alerts sleeping owner to apartment fire\n",
            " - judge rules deputies can't put 'no trick or treat' signs in sex offenders' yards\n",
            " - fdny ems lieutenant who suffered aortic aneurysm while responding to crash released from hospital\n",
            " - kroger accepting visa credit cards again after banning them\n",
            " - 5 charged in alcohol poisoning death of uc irvine fraternity brother\n",
            " - isis names successor to slain leader al baghdadi\n",
            " - 650 people formed a human chain to move children's books from one library to another\n",
            " - girl 7 critically wounded in shooting while trick or treating in little village on southwest side suspect in custody\n",
            " - look of the day\n",
            " - uk police say truck victims from vietnam 3 suspects held\n",
            " - america's gun violence survivors on life after the bullet\n",
            " - will freddie kitchens be one and done in cleveland\n",
            " - maryland man 46 gets probation after he killed a father and his four daughters when his suv crossed a median\n",
            " - queen elizabeth finally had her dream photoshoot thanks to royal dresser angela kelly\n",
            " - cause determined in jessi combs' fatal speed record crash\n",
            " - search for missing nj woman extends to staten island\n",
            " - nina dobrev and screenwriter boyfriend split\n",
            " - pedestrian fatally struck by truck in jersey city\n",
            " - man dies after stabbing in maryland popeyes fight over chicken sandwich sources say\n",
            " - couple cancels wedding keeps 30k as donation for honeymoon instead\n",
            " - minnesota school districts considering 'online snow days'\n",
            " - meghan markle's estranged brother says 'she is only in buckingham palace with harry because of her dad' after he 'paid\n",
            " - us rep ilhan omar divorces husband in minnesota\n",
            " - 911 supervisor playing netflix movie didn't send cops to attempted murder\n",
            " - 1 family's adoption photo shoot is on point but the touching story behind it is everything\n",
            " - air force airman missing after fall into gulf of mexico from c 130 aircraft\n",
            " - lufthansa strike cancels 1 300 flights stranding thousands\n",
            " - holocaust survivor under guard amid death threats\n",
            " - missing college student's parents meet with mother of natalee holloway\n",
            " - philadelphia shooting 10 year old boy shot in head while walking home from school\n",
            " - la firefighter banked 360 010 in overtime pay in one year city audit finds\n",
            " - 'we're standing by it' sheriff doubles down on 'in god we trust' decals after atheist group's complaint\n",
            " - iowan convicted of murder claims his life sentence was served once he died was revived in medical emergency the court\n",
            " - one of fbi's most wanted fugitives offers surrender\n",
            " - mother is freed after 15 years in prison for father's abuse\n",
            "\n",
            "Candidatos (ordenados por score):\n",
            "  (✔) wynonna judd's daughter 23 released from prison 6 years early after being granted parole\n",
            "\n",
            "--- Usuario 5 ---\n",
            "Historial (hasta 1000 ítems):\n",
            " - this guns n' roses video just became the first from the '80s to reach 1 billion youtube views\n",
            " - with carlos beltran hire it's clear the mets learned nothing from the mickey callaway mess\n",
            " - gwyneth paltrow says her feelings about harvey weinstein are complicated\n",
            "\n",
            "Candidatos (ordenados por score):\n",
            "  (✖) survivor contestant accused of 'inappropriate touching ' 2 players admit to using allegations to win\n",
            "  (✖) 'one in a million' deer captured on camera in michigan woods\n",
            "  (✖) wwe wrestler jordan myles quits in expletive filled rant as he brands the company racist\n",
            "  (✔) scarlett johansson regrets being hyper sexualized early in her career\n"
          ]
        }
      ]
    }
  ]
}