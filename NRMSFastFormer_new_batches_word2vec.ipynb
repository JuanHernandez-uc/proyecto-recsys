{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26F6WFf2DqEq",
        "outputId": "3b827f37-72f6-492d-9d3d-2efba9ebc4fd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jRn7tAtvznt-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import defaultdict\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rHFK7Xv7q-I",
        "outputId": "b92a2f32-0635-40cf-84c9-342864e000e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/Colab Notebooks/Sistemas Recomendadores/Proyecto\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEv2zzTb_oHU",
        "outputId": "1357e07d-24ca-45e7-a10d-610ce545569a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " behaviors.tsv\t\t  GoogleNews-vectors-negative300.bin\n",
            " FastFormerNRMS_2.ipynb   news.tsv\n",
            " FastFormerNRMS.ipynb\t 'NRMSFastFormer new batches copy.ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "behavior_path = \"/content/drive/MyDrive/Colab Notebooks/Sistemas Recomendadores/Proyecto/behaviors.tsv\"\n",
        "news_path = \"/content/drive/MyDrive/Colab Notebooks/Sistemas Recomendadores/Proyecto/news.tsv\""
      ],
      "metadata": {
        "id": "3TGgaUYo-4ea"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1tPZIFG41D58"
      },
      "outputs": [],
      "source": [
        "df_behaviors = pd.read_csv(behavior_path, sep=\"\\t\", names=['ImpressionID', 'UserID', 'Time', 'History', 'Impressions'])\n",
        "df_news = pd.read_csv(news_path, sep=\"\\t\", names=['NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'TitleEntities', 'AbstractEntities'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-d0mvuo1Vn_",
        "outputId": "dbfb0821-f5f9-4786-a51d-2516b1c0b90f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2232748, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_behaviors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "65S_yx1t1Wln"
      },
      "outputs": [],
      "source": [
        "df_behaviors[\"Time\"] = pd.to_datetime(df_behaviors[\"Time\"])\n",
        "cutoff = pd.to_datetime(\"2019-11-14\")\n",
        "\n",
        "behavior_train = df_behaviors[df_behaviors[\"Time\"] < cutoff].copy()\n",
        "behavior_val   = df_behaviors[df_behaviors[\"Time\"] >= cutoff].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TW6Z1YS1XjO",
        "outputId": "e0778eda-26b2-4f84-8dbb-1462989b69cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Usando dispositivo: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H50xqCYK1YhW"
      },
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "    tokens = re.findall(r\"[\\w']+\", text.lower())\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE9Fzw-J1ZZO",
        "outputId": "4bfb8707-825a-47fa-91b3-693db589b41e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Títulos con menos de 20 palabras: 100303 de 101527 (98.79%)\n"
          ]
        }
      ],
      "source": [
        "longitudes = df_news[\"Title\"].dropna().apply(lambda x: len(x.split()))\n",
        "cantidad_menor_20 = (longitudes < 20).sum()\n",
        "total = len(longitudes)\n",
        "\n",
        "print(f\"Títulos con menos de 20 palabras: {cantidad_menor_20} de {total} ({cantidad_menor_20 / total:.2%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sWUBzwkT1ahW"
      },
      "outputs": [],
      "source": [
        "word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
        "idx = 2 # Por <UNK> y <PAD>\n",
        "news2idx = {}  # Mapeo: news_id -> lista de índices de palabras (padded/trunc)\n",
        "max_size_title = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upo5CjpX1bW-",
        "outputId": "4e40da60-a26d-424e-e058-f72c213989f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 101527/101527 [00:05<00:00, 17648.54it/s]\n"
          ]
        }
      ],
      "source": [
        "for _, row in tqdm(df_news.iterrows(), total=df_news.shape[0]):\n",
        "    news_id = row[\"NewsID\"]\n",
        "    title = row[\"Title\"]\n",
        "    tokens = [] if pd.isna(title) else tokenize(title)\n",
        "    token_idxs = []\n",
        "    for w in tokens[:max_size_title]:  # truncar título largo\n",
        "        if w not in word2idx:\n",
        "            word2idx[w] = idx\n",
        "            idx += 1\n",
        "        token_idxs.append(word2idx.get(w, word2idx['<UNK>']))\n",
        "    # Rellenar con PAD si es más corto que title_max\n",
        "    if len(token_idxs) < max_size_title:\n",
        "        token_idxs += [word2idx['<PAD>']] * (max_size_title - len(token_idxs))\n",
        "    news2idx[news_id] = token_idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUGgNd7o1can",
        "outputId": "fe0c8cb9-d796-402d-9ac8-5c41478285d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario: 50587 palabras\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(word2idx)\n",
        "print(f'Vocabulario: {vocab_size} palabras')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "behavior_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rLlSQ318D1B3",
        "outputId": "f06eae23-b118-4abe-a6fa-43fbcce495c4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         ImpressionID   UserID                Time  \\\n",
              "0                   1   U87243 2019-11-10 11:30:54   \n",
              "1                   2  U598644 2019-11-12 13:45:29   \n",
              "2                   3  U532401 2019-11-13 11:23:03   \n",
              "3                   4  U593596 2019-11-12 12:24:09   \n",
              "5                   6  U521853 2019-11-11 10:47:31   \n",
              "...               ...      ...                 ...   \n",
              "2232743       2232744  U316192 2019-11-13 18:50:02   \n",
              "2232744       2232745  U451238 2019-11-12 08:54:06   \n",
              "2232745       2232746  U151246 2019-11-13 12:42:51   \n",
              "2232746       2232747  U330725 2019-11-12 13:22:57   \n",
              "2232747       2232748  U500938 2019-11-13 20:10:45   \n",
              "\n",
              "                                                   History  \\\n",
              "0        N8668 N39081 N65259 N79529 N73408 N43615 N2937...   \n",
              "1        N56056 N8726 N70353 N67998 N83823 N111108 N107...   \n",
              "2        N128643 N87446 N122948 N9375 N82348 N129412 N5...   \n",
              "3        N31043 N39592 N4104 N8223 N114581 N92747 N1207...   \n",
              "5        N8668 N29136 N128643 N9740 N9375 N52911 N12090...   \n",
              "...                                                    ...   \n",
              "2232743  N122359 N37069 N95876 N28787 N73408 N11266 N61321   \n",
              "2232744                 N12575 N93816 N71643 N87236 N87236   \n",
              "2232745                                      N27587 N49668   \n",
              "2232746  N121944 N91510 N42280 N60061 N63032 N125223 N4...   \n",
              "2232747  N13311 N73573 N36246 N47118 N71728 N105480 N61...   \n",
              "\n",
              "                                               Impressions  \n",
              "0        N78206-0 N26368-0 N7578-0 N58592-0 N19858-0 N5...  \n",
              "1        N47996-0 N82719-0 N117066-0 N8491-0 N123784-0 ...  \n",
              "2                    N103852-0 N53474-0 N127836-0 N47925-1  \n",
              "3        N38902-0 N76434-0 N71593-0 N100073-0 N108736-0...  \n",
              "5                      N32154-0 N67747-0 N47257-0 N98178-1  \n",
              "...                                                    ...  \n",
              "2232743      N113723-0 N123683-1 N5287-0 N76677-0 N53474-0  \n",
              "2232744                 N18861-0 N20990-0 N43085-0 N7937-1  \n",
              "2232745  N39887-1 N22811-0 N110709-1 N1923-0 N24001-1 N...  \n",
              "2232746  N18947-0 N88808-1 N10012-0 N38902-0 N33078-0 N...  \n",
              "2232747  N24701-0 N13161-0 N39403-0 N40310-0 N5287-0 N1...  \n",
              "\n",
              "[1801231 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89c66613-bf93-4006-928a-64426e323915\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImpressionID</th>\n",
              "      <th>UserID</th>\n",
              "      <th>Time</th>\n",
              "      <th>History</th>\n",
              "      <th>Impressions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>U87243</td>\n",
              "      <td>2019-11-10 11:30:54</td>\n",
              "      <td>N8668 N39081 N65259 N79529 N73408 N43615 N2937...</td>\n",
              "      <td>N78206-0 N26368-0 N7578-0 N58592-0 N19858-0 N5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>U598644</td>\n",
              "      <td>2019-11-12 13:45:29</td>\n",
              "      <td>N56056 N8726 N70353 N67998 N83823 N111108 N107...</td>\n",
              "      <td>N47996-0 N82719-0 N117066-0 N8491-0 N123784-0 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>U532401</td>\n",
              "      <td>2019-11-13 11:23:03</td>\n",
              "      <td>N128643 N87446 N122948 N9375 N82348 N129412 N5...</td>\n",
              "      <td>N103852-0 N53474-0 N127836-0 N47925-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>U593596</td>\n",
              "      <td>2019-11-12 12:24:09</td>\n",
              "      <td>N31043 N39592 N4104 N8223 N114581 N92747 N1207...</td>\n",
              "      <td>N38902-0 N76434-0 N71593-0 N100073-0 N108736-0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>U521853</td>\n",
              "      <td>2019-11-11 10:47:31</td>\n",
              "      <td>N8668 N29136 N128643 N9740 N9375 N52911 N12090...</td>\n",
              "      <td>N32154-0 N67747-0 N47257-0 N98178-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2232743</th>\n",
              "      <td>2232744</td>\n",
              "      <td>U316192</td>\n",
              "      <td>2019-11-13 18:50:02</td>\n",
              "      <td>N122359 N37069 N95876 N28787 N73408 N11266 N61321</td>\n",
              "      <td>N113723-0 N123683-1 N5287-0 N76677-0 N53474-0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2232744</th>\n",
              "      <td>2232745</td>\n",
              "      <td>U451238</td>\n",
              "      <td>2019-11-12 08:54:06</td>\n",
              "      <td>N12575 N93816 N71643 N87236 N87236</td>\n",
              "      <td>N18861-0 N20990-0 N43085-0 N7937-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2232745</th>\n",
              "      <td>2232746</td>\n",
              "      <td>U151246</td>\n",
              "      <td>2019-11-13 12:42:51</td>\n",
              "      <td>N27587 N49668</td>\n",
              "      <td>N39887-1 N22811-0 N110709-1 N1923-0 N24001-1 N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2232746</th>\n",
              "      <td>2232747</td>\n",
              "      <td>U330725</td>\n",
              "      <td>2019-11-12 13:22:57</td>\n",
              "      <td>N121944 N91510 N42280 N60061 N63032 N125223 N4...</td>\n",
              "      <td>N18947-0 N88808-1 N10012-0 N38902-0 N33078-0 N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2232747</th>\n",
              "      <td>2232748</td>\n",
              "      <td>U500938</td>\n",
              "      <td>2019-11-13 20:10:45</td>\n",
              "      <td>N13311 N73573 N36246 N47118 N71728 N105480 N61...</td>\n",
              "      <td>N24701-0 N13161-0 N39403-0 N40310-0 N5287-0 N1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1801231 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89c66613-bf93-4006-928a-64426e323915')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-89c66613-bf93-4006-928a-64426e323915 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-89c66613-bf93-4006-928a-64426e323915');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-75395fbe-09e9-412d-bcf4-76c43aa2ce39\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75395fbe-09e9-412d-bcf4-76c43aa2ce39')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-75395fbe-09e9-412d-bcf4-76c43aa2ce39 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_41805a9c-ca35-4cab-8433-72f02a39bd0f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('behavior_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_41805a9c-ca35-4cab-8433-72f02a39bd0f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('behavior_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "behavior_train"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# TRAIN\n",
        "sessions_train = defaultdict(list)\n",
        "\n",
        "for _, row in tqdm(behavior_train.iterrows(), total=behavior_train.shape[0]):\n",
        "    hist_str = row['History']\n",
        "    hist_ids = [] if pd.isna(hist_str) else hist_str.split()\n",
        "    impr = row['ImpressionID']\n",
        "    imps = row['Impressions'].split() if not pd.isna(row['Impressions']) else []\n",
        "    for imp in imps:\n",
        "        parts = imp.split('-')\n",
        "        if len(parts) == 2:\n",
        "            news_id, click = parts\n",
        "            sessions_train[impr].append((hist_ids, news_id, int(click)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3iBJ45EFqjT",
        "outputId": "652b912d-8ce1-42eb-e6f9-3c41ef175d40"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1801231/1801231 [03:27<00:00, 8662.85it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total impresiones entrenamiento: {len(sessions_train)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr7URKhxGLlt",
        "outputId": "1ee207fa-4b3c-4000-f9ca-f9eaa11fc293"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total impresiones entrenamiento: 1801231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATION\n",
        "sessions_val = defaultdict(list)\n",
        "\n",
        "for _, row in tqdm(behavior_val.iterrows(), total=behavior_val.shape[0]):\n",
        "    hist_str = row['History']\n",
        "    hist_ids = [] if pd.isna(hist_str) else hist_str.split()\n",
        "    impr = row['ImpressionID']\n",
        "    imps = row['Impressions'].split() if not pd.isna(row['Impressions']) else []\n",
        "    for imp in imps:\n",
        "        parts = imp.split('-')\n",
        "        if len(parts) == 2:\n",
        "            news_id, click = parts\n",
        "            sessions_val[impr].append((hist_ids, news_id, int(click)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc8AgIfMGF2G",
        "outputId": "0d4ce54f-f5ea-43ac-d3f8-69313e79ce6a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 431517/431517 [00:50<00:00, 8487.24it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total impresiones validación: {len(sessions_val)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjM4fcbqFs8j",
        "outputId": "ef15d44e-aee6-49d5-e4f2-80590b681224"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total impresiones validación: 431517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ir04iVO71jUm"
      },
      "outputs": [],
      "source": [
        "class MINDListDataset(Dataset):\n",
        "    def __init__(self, sessions, news2idx, word2idx, hist_max, title_max):\n",
        "        self.news2idx  = news2idx\n",
        "        self.word2idx  = word2idx\n",
        "        self.hist_max  = hist_max\n",
        "        self.title_max = title_max\n",
        "\n",
        "        self.sessions = sessions  # dict[impr] = list[(hist, cand, label)]\n",
        "        self.impr_ids = list(sessions.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.impr_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        impr = self.impr_ids[idx]\n",
        "        triples = self.sessions[impr]\n",
        "\n",
        "        # Historial (compartido para todos los candidatos)\n",
        "        hist_ids = triples[0][0][-self.hist_max:]\n",
        "        hist_seq = [self.news2idx.get(nid, [self.word2idx['<PAD>']] * self.title_max) for nid in hist_ids]\n",
        "        while len(hist_seq) < self.hist_max:\n",
        "            hist_seq.insert(0, [self.word2idx['<PAD>']] * self.title_max)\n",
        "\n",
        "        # Candidatos y etiquetas\n",
        "        cand_seqs = []\n",
        "        labels = []\n",
        "        for _, cand_id, lbl in triples:\n",
        "            cand_seqs.append(self.news2idx.get(cand_id, [self.word2idx['<PAD>']] * self.title_max))\n",
        "            labels.append(lbl)\n",
        "\n",
        "        return (torch.tensor(hist_seq,  dtype=torch.long),        # [H,L]\n",
        "                torch.tensor(cand_seqs, dtype=torch.long),        # [C,L]\n",
        "                torch.tensor(labels,   dtype=torch.float),        # [C]\n",
        "                impr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "euYhosJa1kr3"
      },
      "outputs": [],
      "source": [
        "def collate_fn_list(batch):\n",
        "    \"\"\"\n",
        "    Devuelve:\n",
        "        hist_batch  : [B, H, L]\n",
        "        cand_batch  : [B, C_max, L]\n",
        "        label_batch : [B, C_max]  (0/1, padded con -1)\n",
        "        mask_batch  : [B, C_max]  (True donde existe candidato)\n",
        "        impr_batch  : list[str]\n",
        "    \"\"\"\n",
        "    hist_list, cand_list, label_list, impr_list = zip(*batch)\n",
        "\n",
        "    # Historial: tamaño fijo\n",
        "    hist_batch = torch.stack(hist_list)             # [B,H,L]\n",
        "\n",
        "    # Candidatos: pad al máximo C del batch\n",
        "    C_max = max(x.size(0) for x in cand_list)\n",
        "    L     = cand_list[0].size(1)\n",
        "    pad_val = 0  # token PAD\n",
        "\n",
        "    cand_pad   = torch.full((len(batch), C_max, L), pad_val, dtype=torch.long)\n",
        "    label_pad  = torch.full((len(batch), C_max),    -1,      dtype=torch.float)\n",
        "    mask_pad   = torch.zeros(len(batch), C_max,     dtype=torch.bool)\n",
        "\n",
        "    for i,(cands, labels) in enumerate(zip(cand_list, label_list)):\n",
        "        C = cands.size(0)\n",
        "        cand_pad[i,:C]  = cands\n",
        "        label_pad[i,:C] = labels\n",
        "        mask_pad[i,:C]  = 1\n",
        "\n",
        "    return (hist_batch.to(device),\n",
        "            cand_pad.to(device),\n",
        "            label_pad.to(device),\n",
        "            mask_pad.to(device),\n",
        "            list(impr_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4wqU253z1lsn"
      },
      "outputs": [],
      "source": [
        "max_hist_title = 50\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zlFMx44z1mwm"
      },
      "outputs": [],
      "source": [
        "train_dataset = MINDListDataset(sessions_train, news2idx, word2idx, max_hist_title, max_size_title)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_list)\n",
        "\n",
        "val_dataset = MINDListDataset(sessions_val, news2idx, word2idx, max_hist_title, max_size_title)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Lh5_7mMH1nyu"
      },
      "outputs": [],
      "source": [
        "embed_dim = 300\n",
        "num_heads = 20\n",
        "lr = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tkS2TCaQD4J5"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Sistemas Recomendadores/Proyecto/GoogleNews-vectors-negative300.bin\"  # descomprime el .gz\n",
        "word2vec = KeyedVectors.load_word2vec_format(model_path, binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5iMvqeX1o03",
        "outputId": "c03a77d4-4866-45eb-9436-70006b341e7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras encontradas en Word2Vec: 27886/50587\n"
          ]
        }
      ],
      "source": [
        "embedding_matrix = np.random.normal(scale=0.6, size=(vocab_size, embed_dim))\n",
        "found = 0\n",
        "\n",
        "for word, idx in word2idx.items():\n",
        "    if word in word2vec:\n",
        "        embedding_matrix[idx] = word2vec[word]\n",
        "        found += 1\n",
        "\n",
        "print(f\"Palabras encontradas en Word2Vec: {found}/{vocab_size}\")\n",
        "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "gkNJSt3e1pUY"
      },
      "outputs": [],
      "source": [
        "class FastformerAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Atención Fastformer (Atención aditiva global) que reemplaza nn.MultiheadAttention.\n",
        "    Opera con entradas de forma (L, B, E) o (B, L, E), realizando la proyección Q, K, V\n",
        "    por separado, obteniendo vectores globales y propagando interacciones por producto\n",
        "    elemento a elemento, según Fastformer (Fastformer: Additive Attention Can Be All You Need).\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, num_heads, dropout=0.0):\n",
        "        super(FastformerAttention, self).__init__()\n",
        "        assert embed_dim % num_heads == 0, \"embed_dim debe ser divisible por num_heads\"\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        # Proyecciones lineales para Q, K, V (similar a multi-cabeza estándar)\n",
        "        self.W_q = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "        self.W_k = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "        self.W_v = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "        # Parámetros de atención aditiva por cabeza (vectores de peso para Q y K)\n",
        "        # Formato (num_heads, head_dim) para aplicar dot-product con cada vector de dimensión head_dim\n",
        "        self.attn_wq = nn.Parameter(torch.Tensor(num_heads, self.head_dim))\n",
        "        self.attn_wk = nn.Parameter(torch.Tensor(num_heads, self.head_dim))\n",
        "        # Capa de salida tras concatenar cabezas\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # Inicialización\n",
        "        nn.init.xavier_uniform_(self.W_q.weight)\n",
        "        nn.init.xavier_uniform_(self.W_k.weight)\n",
        "        nn.init.xavier_uniform_(self.W_v.weight)\n",
        "        nn.init.xavier_uniform_(self.out_proj.weight)\n",
        "        nn.init.zeros_(self.W_q.bias)\n",
        "        nn.init.zeros_(self.W_k.bias)\n",
        "        nn.init.zeros_(self.W_v.bias)\n",
        "        nn.init.zeros_(self.out_proj.bias)\n",
        "        nn.init.xavier_uniform_(self.attn_wq)\n",
        "        nn.init.xavier_uniform_(self.attn_wk)\n",
        "\n",
        "    def forward(self, query, key, value):\n",
        "        \"\"\"\n",
        "        query, key, value: tensores de forma (L, B, E) ó (S, N, E) donde\n",
        "        L=longitud de secuencia, B=batch, E=embed_dim.\n",
        "        Fastformer es simétrico en q=k=v, pero aceptamos tres argumentos para compatibilidad.\n",
        "        \"\"\"\n",
        "        # Permutar para batch-first: [B, L, E]\n",
        "        transpose = False\n",
        "        if query.dim() == 3 and query.shape[0] != query.shape[1]:\n",
        "            # Asumimos forma (L, B, E)\n",
        "            query = query.transpose(0, 1)\n",
        "            key = key.transpose(0, 1)\n",
        "            value = value.transpose(0, 1)\n",
        "            transpose = True\n",
        "        # Proyectar Q, K, V\n",
        "        # Ahora shapes: [B, L, E]\n",
        "        Q = self.W_q(query)   # [B, L, E]\n",
        "        K = self.W_k(key)     # [B, L, E]\n",
        "        V = self.W_v(value)   # [B, L, E]\n",
        "        B, L, E = Q.size()\n",
        "        H = self.num_heads\n",
        "        D = self.head_dim\n",
        "        # Dividir en cabezas: [B, L, H, D]\n",
        "        Q = Q.view(B, L, H, D)\n",
        "        K = K.view(B, L, H, D)\n",
        "        V = V.view(B, L, H, D)\n",
        "        # Reordenar para [B, H, L, D]\n",
        "        Q = Q.permute(0, 2, 1, 3)\n",
        "        K = K.permute(0, 2, 1, 3)\n",
        "        V = V.permute(0, 2, 1, 3)\n",
        "        # =========== Fastformer Steps ===========\n",
        "        # 1) Atención aditiva sobre Q para obtener q_global [B, H, D]\n",
        "        # Calculamos puntuaciones: sum_{j}( w_q[h,j] * Q[...,j] )\n",
        "        # w_q: [H, D], Q: [B, H, L, D]\n",
        "        # Producto elemento a elemento y sumar sobre dimensión D:\n",
        "        # scores_q: [B, H, L]\n",
        "        scores_q = (Q * self.attn_wq.unsqueeze(0).unsqueeze(2)).sum(dim=-1)  # [B, H, L]\n",
        "        alpha = torch.softmax(scores_q, dim=-1)  # [B, H, L]\n",
        "        # Obtener vector q_global: suma ponderada de Q sobre L\n",
        "        # alpha: [B, H, L], Q: [B, H, L, D] -> q_global: [B, H, D]\n",
        "        q_global = torch.einsum('bhl,bhld->bhd', alpha, Q)\n",
        "        # 2) Interactuar q_global con cada K por producto elemento a elemento -> K'\n",
        "        # Extendemos q_global para cada posición L: [B, H, 1, D] * [B, H, L, D] -> [B, H, L, D]\n",
        "        K_prime = q_global.unsqueeze(2) * K  # [B, H, L, D]\n",
        "        # 3) Atención aditiva sobre K_prime para obtener k_global [B, H, D]\n",
        "        scores_k = (K_prime * self.attn_wk.unsqueeze(0).unsqueeze(2)).sum(dim=-1)  # [B, H, L]\n",
        "        beta = torch.softmax(scores_k, dim=-1)  # [B, H, L]\n",
        "        k_global = torch.einsum('bhl,bhld->bhd', beta, K_prime)  # [B, H, D]\n",
        "        # 4) Interactuar k_global con cada V -> V'\n",
        "        V_prime = k_global.unsqueeze(2) * V  # [B, H, L, D]\n",
        "        # Rearmar V' combinando cabezas: [B, H, L, D] -> [B, L, H*D]\n",
        "        V_prime = V_prime.permute(0, 2, 1, 3).contiguous().view(B, L, H * D)  # [B, L, E]\n",
        "        # Capa lineal de salida y agregar Q (residuo)\n",
        "        out = self.out_proj(V_prime)  # [B, L, E]\n",
        "        # Capa residual: sumamos la proyección original de Q antes de dividir cabezas\n",
        "        # Primero reconstruir Q original (bidimensional por cada posición)\n",
        "        Q_orig = Q.permute(0, 2, 1, 3).contiguous().view(B, L, H * D)  # [B, L, E]\n",
        "        out = out + Q_orig\n",
        "        # Opcional: aplicar dropout\n",
        "        out = self.dropout(out)\n",
        "        # Devolver en forma (L, B, E)\n",
        "        if transpose:\n",
        "            out = out.transpose(0, 1).contiguous()\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "JPmn3pVg11NZ"
      },
      "outputs": [],
      "source": [
        "class NewsEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Codificador de noticias: procesa títulos de noticias (secuencias de tokens)\n",
        "    y produce vectores de noticia. Reemplaza la atención multi-cabeza por FastformerAttention.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, title_max, pretrained_emb=None):\n",
        "        super(NewsEncoder, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.title_max = title_max\n",
        "        # Capa de embedding de palabras\n",
        "        self.word_embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "\n",
        "        if pretrained_emb is not None:\n",
        "            self.word_embedding.weight.data.copy_(pretrained_emb)\n",
        "            self.word_embedding.weight.requires_grad = True  # o False si no quieres fine-tune\n",
        "\n",
        "        # Capa convolucional 1D para extraer características locales de palabras (opcional, similar a arquitectura original)\n",
        "        # Usamos múltiples filtros 1xD para captar n-gramas de tamaño 3 por ejemplo\n",
        "        self.conv = nn.Conv1d(in_channels=embed_dim, out_channels=embed_dim, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        # Atención Fastformer sobre la secuencia de características de palabras\n",
        "        self.self_attn = FastformerAttention(embed_dim, num_heads, dropout=0.1)\n",
        "        # Atención aditiva para agregar las palabras importantes en el título\n",
        "        self.attn_vector = nn.Linear(embed_dim, 1)  # para puntuación de cada palabra\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: tensor de tokens de noticias con forma [B, title_max].\n",
        "        Devuelve: vectores de noticias de forma [B, embed_dim].\n",
        "        \"\"\"\n",
        "        # Embedding y extracción de características locales\n",
        "        # Palabras: [B, title_max, E] -> conv espera [B, E, title_max]\n",
        "        emb = self.word_embedding(x)            # [B, L, E]\n",
        "        emb = emb.transpose(1, 2)               # [B, E, L]\n",
        "        conv_out = self.relu(self.conv(emb))    # [B, E, L]\n",
        "        conv_out = conv_out.transpose(1, 2)     # [B, L, E]\n",
        "        # Atención Fastformer (auto-atención) entre las posiciones de palabras\n",
        "        # FastformerAttention espera (L, B, E) o (B, L, E); adaptamos:\n",
        "        conv_out_trans = conv_out.transpose(0, 1).contiguous()  # [L, B, E]\n",
        "        attn_out = self.self_attn(conv_out_trans, conv_out_trans, conv_out_trans)  # [L, B, E]\n",
        "        attn_out = attn_out.transpose(0, 1)  # [B, L, E]\n",
        "        # Atención aditiva para obtener vector final de noticia\n",
        "        # Calcular puntuación de importancia para cada palabra\n",
        "        scores = self.attn_vector(attn_out).squeeze(-1)  # [B, L]\n",
        "        weights = self.softmax(scores)                    # [B, L]\n",
        "        news_vector = torch.bmm(weights.unsqueeze(1), attn_out).squeeze(1)  # [B, E]\n",
        "        return news_vector  # [B, embed_dim]\n",
        "\n",
        "class UserEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Codificador de usuario: agrega vectores de noticias historiales usando Fastformer.\n",
        "    Toma un historial de noticias y devuelve un vector de usuario.\n",
        "    \"\"\"\n",
        "    def __init__(self, news_encoder, embed_dim, num_heads, hist_max):\n",
        "        super(UserEncoder, self).__init__()\n",
        "        self.news_encoder = news_encoder  # instancia de NewsEncoder para codificar cada noticia\n",
        "        self.hist_max = hist_max\n",
        "        # Atención Fastformer sobre la secuencia de vectores de noticia del historial\n",
        "        self.self_attn = FastformerAttention(embed_dim, num_heads, dropout=0.1)\n",
        "        # Atención aditiva para agregar las noticias más relevantes del historial\n",
        "        self.attn_vector = nn.Linear(embed_dim, 1)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, hist_x):\n",
        "        \"\"\"\n",
        "        hist_x: tensor de tokens de noticias de historial con forma [B, hist_max, title_max].\n",
        "        Devuelve: vector de usuario de forma [B, embed_dim].\n",
        "        \"\"\"\n",
        "        B, H, L = hist_x.size()\n",
        "        # Codificar cada noticia en el historial\n",
        "        hist_x_flat = hist_x.view(B * H, L)                  # [B*H, title_max]\n",
        "        news_vectors = self.news_encoder(hist_x_flat)        # [B*H, embed_dim]\n",
        "        news_vectors = news_vectors.view(B, H, -1)           # [B, hist_max, embed_dim]\n",
        "        # Atención Fastformer sobre las noticias del historial\n",
        "        nv_trans = news_vectors.transpose(0, 1).contiguous() # [H, B, E]\n",
        "        attn_out = self.self_attn(nv_trans, nv_trans, nv_trans)  # [H, B, E]\n",
        "        attn_out = attn_out.transpose(0, 1)                  # [B, H, E]\n",
        "        # Atención aditiva para agregar vectores de noticias importantes\n",
        "        scores = self.attn_vector(attn_out).squeeze(-1)      # [B, H]\n",
        "        weights = self.softmax(scores)                       # [B, H]\n",
        "        user_vector = torch.bmm(weights.unsqueeze(1), attn_out).squeeze(1)  # [B, E]\n",
        "        return user_vector  # [B, embed_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TyZkcEl512j7"
      },
      "outputs": [],
      "source": [
        "class FastformerNRMS(nn.Module):\n",
        "    \"\"\"\n",
        "    Modelo NRMS modificado con Fastformer.\n",
        "    Mantiene la misma interfaz: forward(hist_tensor, cand_tensor).\n",
        "    hist_tensor: [B, hist_max, title_max], cand_tensor: [B, cand_count, title_max].\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, title_max, hist_max, pretrained_emb=None):\n",
        "        super(FastformerNRMS, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.title_max = title_max\n",
        "        self.hist_max = hist_max\n",
        "        # News encoder y user encoder con Fastformer\n",
        "        self.news_encoder = NewsEncoder(vocab_size, embed_dim, num_heads, title_max, pretrained_emb)\n",
        "        self.user_encoder = UserEncoder(self.news_encoder, embed_dim, num_heads, hist_max)\n",
        "        # (Opcional) proyección final o dropout\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, hist_tensor, cand_tensor, mask=None):\n",
        "        \"\"\"\n",
        "        hist_tensor : [B, hist_max, title_max]\n",
        "        cand_tensor : [B, C,       title_max]\n",
        "        mask        : [B, C]  (bool) – True donde el candidato existe\n",
        "        \"\"\"\n",
        "        B, H, L = hist_tensor.size()\n",
        "        _, C, _ = cand_tensor.size()\n",
        "        # Codificar usuario\n",
        "        user_vector = self.user_encoder(hist_tensor)            # [B, E]\n",
        "        # Codificar candidatos (aplicar NewsEncoder a cada candidato)\n",
        "        cand_flat = cand_tensor.view(B * C, L)                  # [B*C, title_max]\n",
        "        cand_vecs = self.news_encoder(cand_flat)               # [B*C, E]\n",
        "        cand_vecs = cand_vecs.view(B, C, -1)                   # [B, cand_count, E]\n",
        "        # Calcular similaridad (producto punto usuario con cada candidato)\n",
        "        # Expandir user_vector para combinar con candidatos\n",
        "\n",
        "        cand_vecs = self.dropout(cand_vecs)\n",
        "        user_vector = self.dropout(user_vector)\n",
        "\n",
        "        user_exp = user_vector.unsqueeze(1)                    # [B, 1, E]\n",
        "        logits = torch.sum(cand_vecs * user_exp, dim=-1)       # [B, cand_count]\n",
        "\n",
        "        if mask is not None:\n",
        "            logits = logits.masked_fill(~mask, -1e9)             # -∞ donde no hay candidato\n",
        "\n",
        "        return logits                                            # [B,C]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ytcEQxLA14d_"
      },
      "outputs": [],
      "source": [
        "model = FastformerNRMS(vocab_size, embed_dim, num_heads, max_size_title, max_hist_title,\n",
        "             pretrained_emb=embedding_matrix.to(device) if embedding_matrix is not None else None)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_tmaqomD2tuG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def ndcg_score(labels, scores, k=5):\n",
        "    order = np.argsort(scores)[::-1]\n",
        "    labels = np.array(labels)\n",
        "    dcg = 0.0\n",
        "    for i in range(min(k, len(labels))):\n",
        "        rel = labels[order[i]]\n",
        "        dcg += (2**rel - 1) / np.log2(i+2)\n",
        "    ideal = np.sort(labels)[::-1]\n",
        "    idcg = 0.0\n",
        "    for i in range(min(k, int(np.sum(labels)))):\n",
        "        idcg += 1.0 / np.log2(i+2)\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "def mrr_score(labels, scores):\n",
        "    order = np.argsort(scores)[::-1]\n",
        "    labels = np.array(labels)[order]\n",
        "    for rank, label in enumerate(labels, start=1):\n",
        "        if label == 1:\n",
        "            return 1.0 / rank\n",
        "    return 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "q64WVk6a2xjO"
      },
      "outputs": [],
      "source": [
        "epochs = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duLvr7fm2yjP",
        "outputId": "994a1fbe-f46b-45af-cbc7-dc8c30747aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1: 100%|██████████| 56289/56289 [3:57:17<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Pérdida promedio: 924497.4263\n",
            "» Nuevo mejor modelo guardado (nDCG@5 = 0.3269)\n",
            "Validación – AUC: 0.6642 | MRR: 0.3506 | nDCG@5: 0.3269 | nDCG@10: 0.3882\n",
            "Modelo con mejor nDCG@5 guardado en nrms_fastformer_best_word2vec.pt\n"
          ]
        }
      ],
      "source": [
        "best_ndcg5 = 0.0\n",
        "best_model_state = None\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for hist_batch, cand_batch, label_batch, mask_batch, _ in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(hist_batch, cand_batch, mask_batch)\n",
        "        target = label_batch.argmax(dim=1)        # [B]\n",
        "        loss = criterion(logits, target)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch} - Pérdida promedio: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluación en validación\n",
        "    if val_loader is None:\n",
        "        continue\n",
        "\n",
        "    model.eval()\n",
        "    ndcg5_list, ndcg10_list, mrr_list, auc_list = [], [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for hist_batch, cand_batch, label_batch, mask_batch, impr_batch in val_loader:\n",
        "            logits  = model(hist_batch, cand_batch, mask_batch)  # [B,C]\n",
        "            scores  = logits.cpu().numpy()\n",
        "            labels  = label_batch.cpu().numpy()\n",
        "            masks   = mask_batch.cpu().numpy()\n",
        "\n",
        "            for s, l, m in zip(scores, labels, masks):\n",
        "                # recortar a candidatos reales\n",
        "                s = s[m]        # (C_real,)\n",
        "                l = l[m]        # (C_real,)\n",
        "\n",
        "                ndcg5_list .append(ndcg_score(l, s, k=5))\n",
        "                ndcg10_list.append(ndcg_score(l, s, k=10))\n",
        "                mrr_list  .append(mrr_score(l, s))\n",
        "                if l.max() > 0 and l.min() == 0:     # al menos 1 pos y 1 neg\n",
        "                    auc_list.append(roc_auc_score(l, s))\n",
        "\n",
        "    ndcg5  = np.mean(ndcg5_list)\n",
        "    ndcg10 = np.mean(ndcg10_list)\n",
        "    mrr    = np.mean(mrr_list)\n",
        "    auc    = np.mean(auc_list) if auc_list else 0.0\n",
        "\n",
        "    if ndcg5 > best_ndcg5:\n",
        "        best_ndcg5 = ndcg5\n",
        "        best_model_state = model.state_dict()\n",
        "        print(f\"» Nuevo mejor modelo guardado (nDCG@5 = {ndcg5:.4f})\")\n",
        "\n",
        "    print(f\"Validación – AUC: {auc:.4f} | MRR: {mrr:.4f} | \"\n",
        "          f\"nDCG@5: {ndcg5:.4f} | nDCG@10: {ndcg10:.4f}\")\n",
        "\n",
        "if best_model_state is not None:\n",
        "    torch.save(best_model_state, \"nrms_fastformer_best_word2vec.pt\")\n",
        "    print(\"Modelo con mejor nDCG@5 guardado en nrms_fastformer_best_word2vec.pt\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}